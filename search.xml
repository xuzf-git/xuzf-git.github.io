<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>XLORE2 大规模跨语言知识图谱构建与应用</title>
      <link href="/20210730undefined/"/>
      <url>/20210730undefined/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/357defdef86a4b45a5ac3426ece54d92.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/357defdef86a4b45a5ac3426ece54d92.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>论文地址：<a href="https://direct.mit.edu/dint/article/1/1/77/9977/XLORE2-Large-scale-Cross-lingual-Knowledge-Graph">XLORE2: Large-scale Cross-lingual Knowledge Graph Construction and Application</a></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>XLORE2 有423974个跨语言链接。相比于XLORE增加了更多的跨语言知识链接、跨语言属性匹配、细粒度类型推断。设计了一个实体链接系统证明了XLORE2的有效性。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>基于Wikipedia，有DBpedia、YAGO、BabelNet等</p><ul><li>YAGO：同一知识的跨语言语义统一性</li><li>DBpedia：跨语言事实三元组的提取和对齐</li><li>BabelNet：实体概念、意义和同义词集。</li></ul><p>维基百科包含的英文知识最多，存在不同语言的知识分布不平衡的问题。为了解决这个问题，XLORE 成为了第一个中英文知识均衡的大规模跨语言知识库。它提供了一种<strong>通过利用维基百科中的跨语言链接来构建跨任何两种语言的知识图谱</strong>的新方法。虽然XLORE已经拥有比较均衡的双语知识量，但仍有大量缺失事实需要补充。主要包括以下三种：</p><ol><li>英文实例和中文实例之间的跨语言链接数量有限。<strong>发现更多的跨语言链接</strong>有利于跨语言的知识共享；</li><li>每个语言版本都维护自己的一组infobox和自己的一组属性，有时还为相应的属性提供不同的值。因此，<strong>必须匹配不同语言的属性</strong>；</li><li>实例的<strong>类型信息不完整</strong>。例如，<em>姚明</em>不仅应该被分配到人、运动员和篮球运动员，还应该被分配到商人。</li></ol><p>相应的工作包括：跨语言知识链接、跨语言属性匹配、细粒度类型推断</p><ol><li>跨语言知识链接：链接不同语言的等效实例</li><li>跨语言属性匹配：实体属性因子图，匹配中英文的属性</li><li>细粒度类型推断：为没有类型信息的实例推断类型（区分类别的subClassOf &amp; instanceOf的类型，使得分类更加准确）</li></ol><p>为了证明XLORE的丰富性，构建了一个高效的实体链接系统XLINK（将文档中的mention链接到各种实体）</p><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><ul><li>DBpedia：<ul><li>语义网 + 关联数据技术</li><li>规模大、覆盖语言广</li><li>定期发布、有一个实时更新的知识库</li></ul></li><li>YAGO：<ul><li>可扩展的语义知识库</li><li>有较高的数据质量</li><li>类型信息：使用 Wikipedia 中的类别来推断实体的类型信息，然后将该类型信息链接到 WordNet</li><li>跨语言属性匹配：将多语言 infobox 属性映射到规范关系，通过 Wikidata 将等效实体合并到规范实体中。</li></ul></li><li>Wikidata：<ul><li>协作编辑的公共数据源</li><li>免费使用</li></ul></li><li>BabelNet：<ul><li>大规模的高覆盖的多语言语义网络</li><li>Wikipedia + WordNet </li><li>通过机器翻译，拓展资源较少的语言知识</li><li>knowledge encode （可用于含知识信息的基于图的词义消歧）</li></ul></li></ul><blockquote><p>XLORE是第一个中英文知识均衡的大型跨语言知识库。</p><p>XLORE2 提高了 XLORE 的数据质量，同时根据 XLORE 中现有的知识推断缺失的事实。</p></blockquote><h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3 方法"></a>3 方法</h2><img src="https://i.loli.net/2021/07/30/NFQXRinCHUlq6Wx.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/NFQXRinCHUlq6Wx.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="构建XLORE2的四个步骤" style="zoom: 33%;" /><ol><li>数据预处理：通过信息抽取，解析出百科数据中的实例、概念、属性、模板</li><li>跨语言知识图谱构建：<ul><li>整合中文维基百科、百度百科、互动百科 <code>---&gt;</code> <strong>中文知识库</strong>（实体、概念、属性、infobox；包含融合和未融合的）</li><li>英文维基百科 <code>---&gt;</code> <strong>英文知识库</strong>（实体、概念、属性、infobox）</li><li>中英文维基链接 <code>--&gt;</code> <strong>跨语言链接</strong></li><li>跨语言知识链接、跨语言属性匹配、细粒度类型推断 <code>---&gt;</code> <strong>跨语言知识图谱</strong></li></ul></li><li>数据质量改善：通过两种 <strong>跨语言知识验证</strong> 的方法提高数据质量<ul><li>预测两个概念之间的 subClassOf 关系是否正确</li><li>预测实例和概念之间的 instanceOf 关系是否正确</li><li>通过 <strong>细粒度类型推断</strong> 推测未融合的实例类型</li></ul></li><li>应用<ul><li>构建了在线系统 <a href="https://www.xlore.org/">XLORE2</a>，</li><li>构建了以使用XLORE2作为主要数据源的双语实体链接应用程序 XLink</li></ul></li></ol><h2 id="4-跨语言知识图谱构建"><a href="#4-跨语言知识图谱构建" class="headerlink" title="4 跨语言知识图谱构建"></a>4 跨语言知识图谱构建</h2><h3 id="4-1-跨语言知识链接"><a href="#4-1-跨语言知识链接" class="headerlink" title="4.1 跨语言知识链接"></a>4.1 跨语言知识链接</h3><p><em>背景</em>：XLORE2 包含 470 万个英文实例和 1000 万个中文实例。目前这两种语言的实例之间只有 424,000 个跨语言链接。</p><p><em>任务</em>：扩展知识链接的任务就是：发现不同语言中的等效实例，并构建起链接。</p><p><em>问题</em>：<strong>特征可扩展性差</strong>（只能把特定的词汇或结构当作特征）和<strong>链接稀疏</strong>（现存的跨语言链接很少）</p><p><em>解决方案</em>：使用基于异构网络表示学习（异构网络嵌入 HNE）的方法，在同一个低维向量空间中表示跨语言实例，从而比较跨语言实例的等效性</p><img src="https://i.loli.net/2021/07/30/UG6zvtYeFW5dh3a.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/UG6zvtYeFW5dh3a.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730145729358" style="zoom:33%;" /><blockquote><ol><li>构建异构网络：在【同义词对应的实例】、【实例之间的链接网络】、【实例和单词之间的语义网络】、【现有的跨语言链接对】之间，构建 <em><strong>文本网络</strong></em></li><li>网络表示学习：学习中英文实例编码</li><li>跨语言链接发现：使用逻辑回归发现中英文之间新的链接</li></ol></blockquote><h3 id="4-2-跨语言属性匹配"><a href="#4-2-跨语言属性匹配" class="headerlink" title="4.2 跨语言属性匹配"></a>4.2 跨语言属性匹配</h3><p><em>背景</em>：不同语言的infobox 可能存在不一致的问题，因此我们选择基于英文维基对其他语言的实例属性进行属性对齐。英文百科中存在超过10万个属性，但是只有不到5%（约5000）的属性存在跨语言（中/英）的映射。</p><p><em>问题</em>：多义属性 、同义属性、不同的单位制、时效性；单靠标签和值不足以进行跨语言属性匹配</p><p><em>解决方案</em>：提出因子图模型，通过显式的链接属性来形式化关联。</p><blockquote><p>左图表示不同语言的知识库的关系图，对角线分隔不同的语言，上层表示属性集、下层表示文章集，上下层之间的链接表示文章使用了属性，属性之间的链接（红色）表示现有的跨语言链接。</p><p>右图表示属性因子图，上层表示观测变量 $x_i$, 下层表示隐藏变量 $y_i$， $x_i$ 表示不同属性的配对，$y_i$ 表示 $x_i$ 链接是否应存在（1或0）；f、g、h 表示三类将关系转换为可计算特征的特征函数。</p></blockquote><p><img src="https://i.loli.net/2021/07/30/wIWJRS2TcmyPxnV.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/wIWJRS2TcmyPxnV.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730152608467"></p><h3 id="4-3-跨语言分类对齐"><a href="#4-3-跨语言分类对齐" class="headerlink" title="4.3 跨语言分类对齐"></a>4.3 跨语言分类对齐</h3><p><em>任务</em>： 对一种语言中的每个概念匹配出另一种语言中最相关的几个概念。</p><p><em>问题</em>： 基于双语主题模型的向量相似性方法只考虑概念的文本上下文，而完全忽略了明确的概念相关性，例如概念与其在文本中的共现词之间的关系，或者分类法中祖先-后代关系的概念之间的关系。</p><p><em>解决方案</em>：直接利用维基百科提供的类别之间的跨语言链接作为概念之间的跨语言链接</p><h2 id="5-数据质量改进"><a href="#5-数据质量改进" class="headerlink" title="5 数据质量改进"></a>5 数据质量改进</h2><h3 id="5-1-跨语言知识验证"><a href="#5-1-跨语言知识验证" class="headerlink" title="5.1 跨语言知识验证"></a>5.1 跨语言知识验证</h3><p>使用一种基于跨语言知识验证的动态自适应增强模型，以迭代地增强分类关系预测的性能。通过学习 $subClassOf$ 预测函数<em>和</em> $instanceOf$​  预测函数将分类关系预测作为一个二元分类问题来处理。</p><p>用于跨语言分类推导的动态自适应增强（DAB）模型如下，基于决策树的二元分类器作为基本学习器</p><img src="https://i.loli.net/2021/07/30/QuzflSRC2GOWIdA.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/QuzflSRC2GOWIdA.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730165046134" style="zoom:50%;" /><h3 id="5-2-细粒度类型推断"><a href="#5-2-细粒度类型推断" class="headerlink" title="5.2 细粒度类型推断"></a>5.2 细粒度类型推断</h3><p>所谓细粒度的类型如下图例子所示：</p><img src="https://i.loli.net/2021/07/30/v5nN8fq7ukM3rUS.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/v5nN8fq7ukM3rUS.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730165406032" style="zoom:50%;" /><p>实现方案为：构建对不同级别的共现信息和标记信息进行编码的异构网络。然后我们通过网络嵌入方法联合学习实例 entity、词 word 和类型 type 表示。</p><p><img src="https://i.loli.net/2021/07/30/s5XAmTvFpdkWIuZ.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/s5XAmTvFpdkWIuZ.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730165635476"></p><h2 id="6-应用"><a href="#6-应用" class="headerlink" title="6 应用"></a>6 应用</h2><p>XLink 是基于 XLORE 的实体链接应用</p><p>一般的实体链接包含：mention detection 和 entity linking 两个步骤</p><ol><li>mention detection：使用解析算法来搜索预先构建的字典来检测提及，使用 Aho-Corasick 算法来解析mention并引入词和实体嵌入，有较高的系统效率。</li><li>entity disambiguation：使用了一种生成概率实体消歧方法，无监督</li></ol><p><img src="https://i.loli.net/2021/07/30/SOqR8hHT2yVAtXk.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/SOqR8hHT2yVAtXk.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730171326167"></p><h2 id="7-系统和数据统计"><a href="#7-系统和数据统计" class="headerlink" title="7 系统和数据统计"></a>7 系统和数据统计</h2><p>XLORE2 的中英文数据统计（包含实例、概念、属性），如下图所示：</p><p><img src="https://i.loli.net/2021/07/30/gvZ9puoka8rbHRj.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/30/gvZ9puoka8rbHRj.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20210730220242056"></p><p>XLORE 使用 RDF 形式存储知识，支持基于关键字和SPARQL查询。XLink 是一个无监督的双语实体链接系统。它进行 mention parse 和实体消歧以将输入文档中的提及链接到 XLORE2 中的实体。</p><p>XLORE 网址：<a href="https://xlore.org/">https://xlore.org</a></p><p>XLink 网址：<a href="https://xlink.xlore.org/">https://xlink.xlore.org</a></p><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h2><p>通过三种方法根据 XLORE 中的现有事实推断缺失的事实：</p><ol><li>利用<strong>异构网络嵌入</strong>方法和<strong>基于回归的模型</strong>来预测新的跨语言链接。</li><li>提出了<strong>实体-属性因子图</strong>来找到英文和中文之间的对应属性，进行跨语言属性匹配</li><li>利用<strong>异构网络嵌入</strong>方法来自动查找实例和概念之间缺失的 $instanceOf$ 关系，进行细粒度类型推断</li></ol>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> deeplearning </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>预训练语言模型-1-简介</title>
      <link href="/2021071944860/"/>
      <url>/2021071944860/</url>
      
        <content type="html"><![CDATA[<img src="https://i.loli.net/2021/07/19/vaP6HKSxDzfshbG.png" class="lazyload" data-srcset="https://i.loli.net/2021/07/19/vaP6HKSxDzfshbG.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="预训练语言模型" style="zoom:50%;" /><blockquote><p>本系列博客为《预训练语言模型》的读书笔记，大部分内容为书籍的内容摘要，也包含部分个人的理解。</p></blockquote><h2 id="1-1-NLP-研究现状"><a href="#1-1-NLP-研究现状" class="headerlink" title="1.1 NLP 研究现状"></a>1.1 NLP 研究现状</h2><p>NLP的里程碑式进展如下：</p>  <!-- tab 自然语言的表示学习发展历程 -->  <div class="timeline">  <div class="timenode"><div class="meta"><p><p>2001年</p></p></div><div class="body"><p>神经语言模型</p></div></div>  <div class="timenode"><div class="meta"><p><p>2008年</p></p></div><div class="body"><p>多任务学习</p></div></div>  <div class="timenode"><div class="meta"><p><p>2013年</p></p></div><div class="body"><ol><li>词嵌入</li><li>神经网络模型</li></ol></div></div>  <div class="timenode"><div class="meta"><p><p>2014年</p></p></div><div class="body"><p>seq2seq 模型</p></div></div>  <div class="timenode"><div class="meta"><p><p>2015年</p></p></div><div class="body"><ol><li>Attention 机制</li><li>基于记忆的网络</li></ol></div></div>  <div class="timenode"><div class="meta"><p><p>2018年</p></p></div><div class="body"><p>预训练语言模型</p></div></div>  </div>  <!-- endtab --><p>绝大部分自然语言任务可与归为一下五类：</p><ol><li>分类任务（Classification）</li><li>匹配任务（Matching）</li><li>翻译任务（Translation）</li><li>结构化预测任务（Structured Prediction）</li><li>序列决策处理（Sequential Decision Process）</li></ol><h2 id="1-2-为什么要使用预训练模型"><a href="#1-2-为什么要使用预训练模型" class="headerlink" title="1.2 为什么要使用预训练模型"></a>1.2 为什么要使用预训练模型</h2><ul><li><p>预训练属于迁移学习，主要思想如下：</p><blockquote><p>神经网络模型的参数不再是随机初始化的，而是通过一些任务进行预训练，得到一套模型参数，然后用这套参数对模型进行初始化，再进行训练。</p></blockquote></li><li><p>对于计算机来说，语言作离散的符号是不能被计算的。因此自然语言处理中，语言的表示问题首当其冲，自然语言的表示学习经历了以下发展：</p>  <!-- tab 自然语言的表示学习发展历程 -->  <div class="timeline">    <div class="timenode"><div class="meta"><p><p>1948年</p></p></div><div class="body"><p>基于统计的语言模型：n-gram 模型</p></div></div>    <div class="timenode"><div class="meta"><p><p>1954年</p></p></div><div class="body"><ol><li>分布式理论：上下文相似的词，其语义也相似</li><li>词袋模型</li></ol></div></div>    <div class="timenode"><div class="meta"><p><p>1986年</p></p></div><div class="body"><p>分布式表示：文本的一种表示方式，相比于one-hot编码，分布式表示将文本在更低的维度上表示</p></div></div>    <div class="timenode"><div class="meta"><p><p>2003年</p></p></div><div class="body"><p>神经概率语言模型</p></div></div>    <div class="timenode"><div class="meta"><p><p>2013年</p></p></div><div class="body"><p>word2vec</p></div></div>    <div class="timenode"><div class="meta"><p><p>2018年</p></p></div><div class="body"><p>预训练语言模型</p></div></div>    </div>  <!-- endtab --><p>总结自然语言表示学习的发展，大致分为以下三个阶段</p><ol><li>基于统计的语言模型：n-gram 模型</li><li>基于大规模文本数据训练得到的分布式表示：word2vec、Glove等【第一代预训练语言模型】</li><li>考虑上下文信息的词向量表示：ELMo（Bi-LSTM）、Transformer（Attention）【第二代预训练语言模型】</li></ol><blockquote><p>第一代预训练语言模型如 word2vec 对于词语的表示是固定的（词向量固定），忽视了在不同上下文中词语的多义性，第二代预训练模型考虑了词语的上下文信息。</p></blockquote></li><li><p>区分两类预训练模型：自回归 vs 自编码</p><blockquote><ul><li>自回归：根据上文预测下一个词，或者根据下文预测上一个词，如ELMo</li><li>自编码：又称“降噪自编码模型”，在输入中随机掩盖一个单词（相当于加入噪声），在预训练中根据上下文预测被掩码词，可以认为是一个降噪。</li></ul></blockquote><p>ELMo、GPT、XLNet属于自回归模型；BERT、ERNINE、RoBERTa属于自编码模型</p></li><li><p>预训练语言模型和视觉模型相似，随着模型由浅至深，特征也更加具体。</p><ul><li>语法信息（词性、成分、依存）在模型的浅层</li><li>语义信息（共指消解、语义原型）在模型的深层</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch实现第一个生成对抗网络（GAN）</title>
      <link href="/2021051045777/"/>
      <url>/2021051045777/</url>
      
        <content type="html"><![CDATA[<p>以训练一个形如 “1010” 格式的向量生成器为例，使用Pytorch实现第一个GAN</p><span id="more"></span><h2 id="1、GAN-原理"><a href="#1、GAN-原理" class="headerlink" title="1、GAN 原理"></a>1、GAN 原理</h2><p>以训练一个形如 “1010” 格式的向量生成器为例：</p><p>需要构造两个神经网络为：生成器（Generator）和判别器（Discriminator）其中，</p><ol><li>生成器接受随机噪声，并据此生成一个size=4的向量。</li><li>判别器判断接受的向量是真实样本还是生成器的生成样本，给出输入是真实样本的概率</li></ol><p>在训练过程中，生成器的目标是尽量生成真实的数据去欺骗判别器。而判别器的目标就是尽量把生成数据和真实样本区分开。训练过程实际上可以理解为生成器和判别器的博弈。</p><p>训练的最终目标：生成器能够生成足以“以假乱真”的数据，判别器不能区分输入的数据是真实数据还是生成数据，原理图如下：<br><img src="https://img-blog.csdnimg.cn/20210509191002901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210509191002901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="GAN"></p><h2 id="2、生成器-amp-判别器"><a href="#2、生成器-amp-判别器" class="headerlink" title="2、生成器 &amp; 判别器"></a>2、生成器 &amp; 判别器</h2><p>判别器和生成器选择了最简单的MLP网络，隐藏层都设置为包含3个神经元（非必须）</p><pre><code class="python"># 判别器class Discriminator(nn.Module):    def __init__(self):        # 调用父类的构造函数，初始化父类        super().__init__()        # 定义神经网络        self.model = nn.Sequential(            nn.Linear(4, 3),            nn.Sigmoid(),            nn.Linear(3, 1),             nn.Sigmoid()        )        # 创建损失函数        self.loss_function = nn.MSELoss()        # 创建优化器，随机梯度下降        self.optimiser = torch.optim.SGD(self.parameters(), lr=0.01)            def forward(self, inputs):        return self.model(inputs)            def train(self, inputs, targets):        # 计算网络的输出值        outputs = self.forward(inputs)        loss = self.loss_function(outputs, targets)        # 反向传播        self.optimiser.zero_grad()        loss.backward()        self.optimiser.step()</code></pre><pre><code class="python"># 生成器class Generator(nn.Module):    def __init__(self):        super().__init__()        # 定义神经网络        self.model = nn.Sequential(            nn.Linear(1, 3),            nn.Sigmoid(),            nn.Linear(3, 4),            nn.Sigmoid()        )        # 创建优化器，随机梯度下降        self.optimiser = torch.optim.SGD(self.parameters(), lr=0.01)            def forward(self, inputs):        return self.model(inputs)            def train(self, discriminator, inputs, targets):        # 生成器输出        gen_data = self.forward(inputs)        # 判别器预测        pred_data = discriminator(gen_data)        # 计算损失        self.optimiser.zero_grad()        loss = discriminator.loss_function(pred_data, targets)        # 从判别器误差开始，反向传播误差梯度到生成器        loss.backward()        # 用生成器的优化器更新自身参数        self.optimiser.step()</code></pre><h2 id="3、GAN的训练方法"><a href="#3、GAN的训练方法" class="headerlink" title="3、GAN的训练方法"></a>3、GAN的训练方法</h2><p>训练一个GAN需要实现判别器和生成器的同步优化。如果判别器的分类能力很强，生成器的分类能力很弱，不能很好地训练生成器，反之亦然。</p><p>一般来说，GAN每个step的训练包含三个步骤：</p><ol><li>使用真实样本训练判别器（提高判别器识别真实样本的能力）</li><li>使用生成样本训练判别器（提高判别器识别生成样本的能力）</li><li>训练生成器（提高生成器生成样本的能力）</li></ol><p>代码示例如下：</p><pre><code class="python"># 生成1010格式的训练正样本(引入高斯噪声)def generate_real():    real_data = torch.FloatTensor([        random.uniform(0.8, 1.0),        random.uniform(0.0, 0.2),        random.uniform(0.8, 1.0),        random.uniform(0.0, 0.2),    ])    return real_data# 创建判别器和生成器discriminator = Discriminator()generator = Generator()for i in range(10000):    # 用真实样本训练判别器， target=1    discriminator.train(generate_real(), torch.FloatTensor([1.0]))    # 用生成样本训练判别器， target=0    discriminator.train(        generator(torch.FloatTensor([0.5])).detach(),         torch.FloatTensor([0.0])    )    # 训练生成器， target=1    generator.train(        discriminator,         torch.FloatTensor([0.5]),         torch.FloatTensor([1.0])    )</code></pre><p>代码解析：</p><ol><li>训练前两步的 target 分别取 1、0 很好理解，就是分别用正样本、负样本训练判别网络。</li><li>对于第三步中 target 取为 1  可以有如下理解：如果生成网络成功欺骗过判别器，则对其奖励，反之惩罚；<br>所谓的“成功欺骗”就是判别网络对于生成样本的预测的判别结果为 1，所以 target 取 1。</li><li>使用判别器的loss function计算loss，梯度传播到生成器，利用生成器的优化器更新参数，判别器的参数保持不变。</li><li>第二步中的 <code>detach</code> 是将梯度的传播在计算图上阻断，避免计算生成网络中的梯度，节省计算成本。具体用法可以参考<a href="https://pytorch.org/docs/master/generated/torch.Tensor.detach.html">pytorch’doc——Tensor.detach()</a></li></ol><h2 id="4、效果分析"><a href="#4、效果分析" class="headerlink" title="4、效果分析"></a>4、效果分析</h2><p>生成结果如下：<br><img src="https://img-blog.csdnimg.cn/2021050919380096.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/2021050919380096.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="生成结果"></p><p>判别器loss变换如下：<br><img src="https://img-blog.csdnimg.cn/20210509194022289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210509194022289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"></p><p>趋势分析：</p><ol><li>从0.25 下降，表示判别器的识别能力增强，之后再次上升到0.25，表示生成的样本更能“以假乱真”。</li><li>收敛到0.25的原因：采用MSE损失函数，在判断不出来的时候选择介于0~1中间的0.5作为输出，此时的loss为0.25</li></ol><p><strong>完整代码，以及更多示例参见 Github</strong>: <a href="https://github.com/xuzf-git/Algorithm-Toy">https://github.com/xuzf-git/Algorithm-Toy</a></p>]]></content>
      
      
      <categories>
          
          <category> cv </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> DeepLearning </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Hmm模型和Viterbi算法的中文分词和词性标注</title>
      <link href="/2021021852960/"/>
      <url>/2021021852960/</url>
      
        <content type="html"><![CDATA[<p>使用 python 实现基于Hmm模型和Viterbi算法的中文分词及词性标注；使用最大概率算法进行优化。最终效果：人民日报语料：分词(F1:96.189%)；词性标注(F1:97.934%)</p><span id="more"></span><p>完整代码和数据，参见本实验的 github地址：<a href="https://github.com/xuzf-git/WordSegment-and-PosTag">https://github.com/xuzf-git/WordSegment-and-PosTag</a></p><h2 id="1、基于统计的分词方法（隐马尔可夫模型）"><a href="#1、基于统计的分词方法（隐马尔可夫模型）" class="headerlink" title="1、基于统计的分词方法（隐马尔可夫模型）"></a>1、基于统计的分词方法（隐马尔可夫模型）</h2><div id="1、基于统计的分词方法（隐马尔可夫模型）"></div><h3 id="（1）算法设计"><a href="#（1）算法设计" class="headerlink" title="（1）算法设计"></a>（1）算法设计</h3><p> 采用隐马尔科夫（Hmm）模型进行统计分词。使用BMES标注方法，<font color=red>将分词任务转换为字标注的问题</font>，通过对每个字进行标注得到词语的划分。具体来说，<font color=red>BMES标注方法</font>是用“B、M、E、S”四种标签对词语中不同位置的字符进行标注，<font color=red>B表示一个词的词首位置，M表示一个词的中间位置，E表示一个词的末尾位置，S表示一个单独的字</font>。<br> 字标注的问题可视为隐马尔可夫模型中的解码问题。句子的BMES标注序列作为隐藏状态序列，句子的字符序列作为可观测序列，通过以下两个步骤实现分词：</p><ol><li><p>学习模型参数<br>对预料进行统计，获得隐藏状态的转移概率矩阵trans、发射概率矩阵emit 、初始状态矩阵start</p><ol><li>观测序列 $O$ ：句子的字符序列 $[w_0,w_1,……w_n]$</li><li>隐藏序列 $S$：BMES标注序列 $[p_0,p_1,……p_n]$</li><li>初始概率 $\pi$ ：$start(i)=P_{(p_0=i)}=count(p_0=i)/count(sentence) \quad i\in{B、M、E、D}$</li><li>转移概率 $trans$ ：$trans(i,j)=P(j│i)=count(p_k=i ,p_{k+1}=j)/count(i)     i,j \in{B、M、E、D}$</li><li>发射概率 $emit$ ：$emit(i,w)=P(w│i)=count(state(w)=i)/count(i) \quad i\in{B、M、E、D}$,</li></ol></li><li><p>使用 Viterbi 算法预测<br>Viterbi算法是用动态规划的方法求解最优的标注序列。<font color=red>每个标注序列视为从句首到句尾的一个路径，通过Viterbi算法获取概率最大的路径</font>，在主要由以下几步实现：</p><ol><li>状态$dp[i][j]$：表示第$i$个字符，标签为$j$ 的所有路径中的最大概率。</li><li>记录路径 $path[i][j]$：表示$dp[i][j]$为最大概率时，第$i-1$个字符的标签</li><li>状态初始化：$dp[0][j] =start(j) emit(j,w_0)$</li><li>递推（状态转移方程）：$dp[i][j]=   max_{k\in {pos}}⁡(dp[i-1][k]×trans[k,j])  × emit[j,w_i]$</li><li>记录路径：$path[i][j]=arg⁡max_{k∈{pos}}⁡(dp[i-1][k]×trans[k,j])$ </li><li>回溯最优路径：$p_i=path[i+1][p_(i+1) ] \quad i=n-1,n-2,……1,0$</li><li>输出最优路径：$[p_1,p_2……p_n]$</li></ol></li></ol><h3 id="（2）程序结构"><a href="#（2）程序结构" class="headerlink" title="（2）程序结构"></a>（2）程序结构</h3><pre><code class="python">import timeimport jsonimport pandas as pdclass Hmm:    def __init__(self):        self.trans_p = &#123;&#39;S&#39;: &#123;&#125;, &#39;B&#39;: &#123;&#125;, &#39;M&#39;: &#123;&#125;, &#39;E&#39;: &#123;&#125;&#125;        self.emit_p = &#123;&#39;S&#39;: &#123;&#125;, &#39;B&#39;: &#123;&#125;, &#39;M&#39;: &#123;&#125;, &#39;E&#39;: &#123;&#125;&#125;        self.start_p = &#123;&#39;S&#39;: 0, &#39;B&#39;: 0, &#39;M&#39;: 0, &#39;E&#39;: 0&#125;        self.state_num = &#123;&#39;S&#39;: 0, &#39;B&#39;: 0, &#39;M&#39;: 0, &#39;E&#39;: 0&#125;        self.state_list = [&#39;S&#39;, &#39;B&#39;, &#39;M&#39;, &#39;E&#39;]        self.line_num = 0        self.smooth = 1e-6    @staticmethod    def __state(word):        &quot;&quot;&quot;获取词语的BOS标签，标注采用 4-tag 标注方法，        tag = &#123;S,B,M,E&#125;，S表示单字为词，B表示词的首字，M表示词的中间字，E表示词的结尾字        Args:            word (string): 函数返回词语 word 的状态标签        &quot;&quot;&quot;        if len(word) == 1:            state = [&#39;S&#39;]        else:            state = list(&#39;B&#39; + &#39;M&#39; * (len(word) - 2) + &#39;E&#39;)        return state    def train(self, filepath, save_model=False):        &quot;&quot;&quot;训练hmm, 学习发射概率、转移概率等参数        Args:            save_model: 是否保存模型参数            filepath (string): 训练预料的路径        &quot;&quot;&quot;        print(&quot;正在训练模型……&quot;)        start_time = time.thread_time()        with open(filepath, &#39;r&#39;, encoding=&#39;utf8&#39;) as f:            for line in f.readlines():                self.line_num += 1                line = line.strip().split()                # 获取观测（字符）序列                char_seq = list(&#39;&#39;.join(line))                # 获取状态（BMES）序列                state_seq = []                for word in line:                    state_seq.extend(self.__state(word))                # 判断是否等长                assert len(char_seq) == len(state_seq)                # 统计参数                for i, s in enumerate(state_seq):                    self.state_num[s] = self.state_num.get(s, 0) + 1.0                    self.emit_p[s][char_seq[i]] = self.emit_p[s].get(                        char_seq[i], 0) + 1.0                    if i == 0:                        self.start_p[s] += 1.0                    else:                        last_s = state_seq[i - 1]                        self.trans_p[last_s][s] = self.trans_p[last_s].get(                            s, 0) + 1.0        # 归一化：        self.start_p = &#123;            k: (v + 1.0) / (self.line_num + 4)            for k, v in self.start_p.items()        &#125;        self.emit_p = &#123;            k: &#123;w: num / self.state_num[k]                for w, num in dic.items()&#125;            for k, dic in self.emit_p.items()        &#125;        self.trans_p = &#123;            k1: &#123;k2: num / self.state_num[k1]                 for k2, num in dic.items()&#125;            for k1, dic in self.trans_p.items()        &#125;        end_time = time.thread_time()        print(&quot;训练完成，耗时 &#123;:.3f&#125;s&quot;.format(end_time - start_time))        # 保存参数        if save_model:            parameters = &#123;                &#39;start_p&#39;: self.start_p,                &#39;trans_p&#39;: self.trans_p,                &#39;emit_p&#39;: self.emit_p            &#125;            jsonstr = json.dumps(parameters, ensure_ascii=False, indent=4)            param_filepath = &quot;./data/HmmParam_Token.json&quot;            with open(param_filepath, &#39;w&#39;, encoding=&#39;utf8&#39;) as jsonfile:                jsonfile.write(jsonstr)    def viterbi(self, text):        &quot;&quot;&quot;Viterbi 算法        Args:            text (string): 句子        Returns:            list: 最优标注序列        &quot;&quot;&quot;        text = list(text)        dp = pd.DataFrame(index=self.state_list)        # 初始化 dp 矩阵 (prop，last_state)        dp[0] = [(self.start_p[s] * self.emit_p[s].get(text[0], self.smooth),                  &#39;_start_&#39;) for s in self.state_list]        # 动态规划地更新 dp 矩阵        for i, ch in enumerate(text[1:]):  # 遍历句子中的每个字符 ch            dp_ch = []            for s in self.state_list:  # 遍历当前字符的所有可能状态                emit = self.emit_p[s].get(ch, self.smooth)                # 遍历上一个字符的所有可能状态，寻找经过当前状态的最优路径                (prob, last_state) = max([                    (dp.loc[ls, i][0] * self.trans_p[ls].get(s, self.smooth) *                     emit, ls) for ls in self.state_list                ])                dp_ch.append((prob, last_state))            dp[i + 1] = dp_ch        # 回溯最优路径        path = []        end = list(dp[len(text) - 1])        back_point = self.state_list[end.index(max(end))]        path.append(back_point)        for i in range(len(text) - 1, 0, -1):            back_point = dp.loc[back_point, i][1]            path.append(back_point)        path.reverse()        return path    def cut(self, text):        &quot;&quot;&quot;根据 viterbi 算法获得状态，根据状态切分句子        Args:            text (string): 待分词的句子        Returns:            list: 分词列表        &quot;&quot;&quot;        state = self.viterbi(text)        cut_res = []        begin = 0        for i, ch in enumerate(text):            if state[i] == &#39;B&#39;:                begin = i            elif state[i] == &#39;E&#39;:                cut_res.append(text[begin:i + 1])            elif state[i] == &#39;S&#39;:                cut_res.append(text[i])        return cut_res# if __name__ == &quot;__main__&quot;:#     hmm = Hmm()#     hmm.train(&#39;./data/PeopleDaily_Token.txt&#39;, save_model=True)#     cutres = hmm.cut(&#39;中央电视台收获一批好剧本&#39;)#     print(cutres)</code></pre><h2 id="2、基于字典的分词方法（最短路分词模型）"><a href="#2、基于字典的分词方法（最短路分词模型）" class="headerlink" title="2、基于字典的分词方法（最短路分词模型）"></a>2、基于字典的分词方法（最短路分词模型）</h2><h3 id="（1）-算法设计"><a href="#（1）-算法设计" class="headerlink" title="（1）  算法设计"></a>（1）  算法设计</h3><p>最短路分词模型的主要思想是<font color=red>将句子中的所有字符当作节点，根据字典找出句子中所有的词语，将词语两端的字符连接起来，构成从词首指向词尾的一条边。通过找出所有的候选词，构建出一个有向无环图（DAG）。找到从句首字符到句尾字符的最短路径，即可作为句子的分词结果。</font>最短路径分词方法采用的规则使切分出来的词数最少，符合汉语自身的规律。</p><p>最短路分词算法，由以下几个步骤实现：</p><ol><li>构造句子的切分图，如果句子 $sentence$ 的子串 $w[i:j]$ 在词典中，则添加边 $V(i,j)$，得到句子的有向无环图 DAG</li><li> 采用Dijkstra 算法动态规划地求解最短路径，$dp[i]$  表示DAG中句首到第 $i$ 个字符的路径长度</li><li> 状态转移函数如下: $dp[i] = min{dp[j-1] + 1}$ ；其中：$i$ 为当前边的起点，$j$ 为当前边的终点。</li><li>回溯最优路径</li></ol><h3 id="（2）程序结构-1"><a href="#（2）程序结构-1" class="headerlink" title="（2）程序结构"></a>（2）程序结构</h3><pre><code class="python">import jsonimport mathimport timeclass ShortTokenizer:    def __init__(self, use_freq=True):        self.word_freq = &#123;&#125;        self.word_num = 0        self.use_freq = use_freq    def train(self, filepath, trained=False):        &quot;&quot;&quot;根据训练语料统计词频        Args:            filepath (string): 训练语料文件路径            trained (bool): 模型是否已经训练        &quot;&quot;&quot;        if not trained:            # 统计词频            print(&quot;正在训练模型……&quot;)            stime = time.thread_time()            with open(filepath, &#39;r&#39;, encoding=&#39;utf8&#39;) as f:                for line in f.readlines():                    line = line.strip().split()                    self.word_num += len(line)                    self.word_freq.update(&#123;i: self.word_freq.get(i, 0) + 1 for i in line&#125;)            etime = time.thread_time()            print(&quot;训练完成，耗时&#123;&#125;s&quot;.format(etime - stime))            # 保存词频            jsonstr = json.dumps(self.word_freq, ensure_ascii=False, indent=4)            with open(&#39;./data/word_freq_npath.json&#39;, &#39;w&#39;,                      encoding=&#39;utf8&#39;) as f:                f.write(jsonstr)        else:            # 读入词频            with open(filepath, &#39;r&#39;, encoding=&#39;utf8&#39;) as f:                jsonstr = &#39;&#39;.join(f.readlines())                self.word_freq = json.loads(jsonstr)                self.word_num = sum(self.word_freq.values())    def __weight(self, word):        &quot;&quot;&quot;计算word的词频 -log(P(w)) = log(num) - log(k_w)        Args:            word (string): 切分的词语，切分图上的一条边        Returns:            float: 词典中存在该词返回 -log(P)，否则返回0        &quot;&quot;&quot;        freq = self.word_freq.get(word, 0)        if freq and self.use_freq:            return math.log(self.word_num) - math.log(freq)        elif freq:            return 1        else:            return 0    def Token(self, sentence):        &quot;&quot;&quot;结合统计信息的最短路分词函数（最大概率分词）        Args:            sentence (string): 待切分的句子        Returns:            list: 切分的词语，构成的 list        &quot;&quot;&quot;        length = len(sentence)        # 构造句子的切分图        graph = &#123;&#125;        for i in range(length):            graph[i] = []            for j in range(i):                freq = self.__weight(sentence[j:i + 1])                if freq:                    graph[i].append((j, freq))        # 动态规划求解最优路径 ( arg min[-log(P)] )        # 初始化DP矩阵        dp = [(i, self.__weight(sentence[i])) for i in range(length)]        dp.insert(0, (-1, 0))        # 状态转移函数：dp[i] = min&#123;dp[j-1] + weight(sentence[j:i])&#125;        # i：为当前词的词尾；j: 为当前词的词头        for i in range(2, len(dp)):            index = dp[i][0]            cost = dp[i][1] + dp[i - 1][1]            for j, freq in graph[i - 1]:                if freq + dp[j][1] &lt; cost:                    cost = freq + dp[j][1]                    index = j            dp[i] = (index, cost)        # 回溯最优路径        token_res = []        break_p = length        while break_p &gt; 0:            token_res.append(sentence[dp[break_p][0]:break_p])            break_p = dp[break_p][0]        token_res.reverse()        return token_res# if __name__ == &quot;__main__&quot;:#     Tokenizer = ShortTokenizer()#     # Tokenizer.train(&#39;./data/PeopleDaily_Token.txt&#39;)#     Tokenizer.train(&#39;./data/word_freq_npath.json&#39;, trained=True)#     Tokenizer.Token(&#39;迈向充满希望的新世纪&#39;)#     Tokenizer.Token(&#39;１９９７年，是中国发展历史上非常重要的很不平凡的一年。&#39;)</code></pre><h2 id="3、改进最短路分词模型（最大概率模型）"><a href="#3、改进最短路分词模型（最大概率模型）" class="headerlink" title="3、改进最短路分词模型（最大概率模型）"></a>3、改进最短路分词模型（最大概率模型）</h2><h3 id="（1）算法设计-1"><a href="#（1）算法设计-1" class="headerlink" title="（1）算法设计"></a>（1）算法设计</h3><p>最短路分词方法构建有向无环图DAG的过程中，只要词语在字典中出现即可添加边，忽略了成词的概率。现在考虑成词的概率，通过极大似然估计，<font color=red>以词频表示成词概率，为DAG的每条边赋予权重，优化分词结果。通过 Dijkstra 算法求得的带权最短路径即为所有分词结果中概率最大的分词方法。</font>该分词方法本质上是使用了1-gram文法的最大概率分词模型。</p><h3 id="（2）程序结构-2"><a href="#（2）程序结构-2" class="headerlink" title="（2）程序结构"></a>（2）程序结构</h3><p>同最短路分词模型的实现程序，实例化模型时传入 <code>use_freq = True</code> 参数。</p><h2 id="4、隐马尔可夫模型进行词性标注"><a href="#4、隐马尔可夫模型进行词性标注" class="headerlink" title="4、隐马尔可夫模型进行词性标注"></a>4、隐马尔可夫模型进行词性标注</h2><h4 id="（1）算法设计-2"><a href="#（1）算法设计-2" class="headerlink" title="（1）算法设计"></a>（1）算法设计</h4><p>词性标注是序列标注问题，可采用Hmm模型的解码问题的解决方法。将词性序列作为隐藏序列，将词语序列作为观测序列，同过Viterbi算法预测最优的词性序列。算法实现步骤同 <a href="#1%E3%80%81%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95%EF%BC%88%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%89">1、基于统计的分词方法（隐马尔可夫模型）</a></p><h4 id="（2）程序结构-3"><a href="#（2）程序结构-3" class="headerlink" title="（2）程序结构"></a>（2）程序结构</h4><pre><code class="python">import jsonimport mathimport pandas as pdclass HmmPosTag:    def __init__(self):        self.trans_prop = &#123;&#125;        self.emit_prop = &#123;&#125;        self.start_prop = &#123;&#125;        self.poslist = []        self.trans_sum = &#123;&#125;        self.emit_sum = &#123;&#125;    def __upd_trans(self, curpos, nxtpos):        &quot;&quot;&quot;更新转移概率矩阵        Args:            curpos (string): 当前词性            nxtpos (string): 下一词性        &quot;&quot;&quot;        if curpos in self.trans_prop:            if nxtpos in self.trans_prop[curpos]:                self.trans_prop[curpos][nxtpos] += 1            else:                self.trans_prop[curpos][nxtpos] = 1        else:            self.trans_prop[curpos] = &#123;nxtpos: 1&#125;    def __upd_emit(self, pos, word):        &quot;&quot;&quot;更新发射概率矩阵        Args:            pos (string): 词性            word (string): 词语        &quot;&quot;&quot;        if pos in self.emit_prop:            if word in self.emit_prop[pos]:                self.emit_prop[pos][word] += 1            else:                self.emit_prop[pos][word] = 1        else:            self.emit_prop[pos] = &#123;word: 1&#125;    def __upd_start(self, pos):        &quot;&quot;&quot;更新初始状态矩阵        Args:            pos (string): 初始词语的词性        &quot;&quot;&quot;        if pos in self.start_prop:            self.start_prop[pos] += 1        else:            self.start_prop[pos] = 1    def train(self, data_path):        &quot;&quot;&quot;训练 hmm 模型、求得转移矩阵、发射矩阵、初始状态矩阵        Args:            data_path (string): 训练数据的路径        &quot;&quot;&quot;        f = open(data_path, &#39;r&#39;, encoding=&#39;utf-8&#39;)        for line in f.readlines():            line = line.strip().split()            # 统计初始状态的概率            self.__upd_start(line[0].split(&#39;/&#39;)[1])            # 统计转移概率、发射概率            for i in range(len(line) - 1):                self.__upd_emit(line[i].split(&#39;/&#39;)[1], line[i].split(&#39;/&#39;)[0])                self.__upd_trans(line[i].split(&#39;/&#39;)[1], line[i + 1].split(&#39;/&#39;)[1])            i = len(line) - 1            self.__upd_emit(line[i].split(&#39;/&#39;)[1], line[i].split(&#39;/&#39;)[0])        f.close()        # 记录所有的 pos        self.poslist = list(self.emit_prop.keys())        self.poslist.sort()        # 统计 trans、emit 矩阵中各个 pos 的归一化分母        num_trans = [            sum(self.trans_prop[key].values()) for key in self.trans_prop        ]        self.trans_sum = dict(zip(self.trans_prop.keys(), num_trans))        num_emit = [            sum(self.emit_prop[key].values()) for key in self.emit_prop        ]        self.emit_sum = dict(zip(self.emit_prop.keys(), num_emit))    def predict(self, sentence):        &quot;&quot;&quot;Viterbi 算法预测词性        Args:            sentence (string): 分词后的句子（空格隔开）        Returns:            list: 词性标注序列         &quot;&quot;&quot;        sentence = sentence.strip().split()        posnum = len(self.poslist)        dp = pd.DataFrame(index=self.poslist)        path = pd.DataFrame(index=self.poslist)        # 初始化 dp 矩阵（DP 矩阵: posnum * wordsnum 存储每个 word 每个 pos 的最大概率）        start = []        num_sentence = sum(self.start_prop.values()) + posnum        for pos in self.poslist:            sta_pos = self.start_prop.get(pos, 1e-16) / num_sentence            sta_pos *= (self.emit_prop[pos].get(sentence[0], 1e-16) /                        self.emit_sum[pos])            sta_pos = math.log(sta_pos)            start.append(sta_pos)        dp[0] = start        # 初始化 path 矩阵        path[0] = [&#39;_start_&#39;] * posnum        # 递推        for t in range(1, len(sentence)):  # 句子中第 t 个词            prob_pos, path_point = [], []            for i in self.poslist:  # i 为当前词的 pos                max_prob, last_point = float(&#39;-inf&#39;), &#39;&#39;                emit = math.log(self.emit_prop[i].get(sentence[t], 1e-16) / self.emit_sum[i])                for j in self.poslist:  # j 为上一次的 pos                    tmp = dp.loc[j, t - 1] + emit                    tmp += math.log(self.trans_prop[j].get(i, 1e-16) / self.trans_sum[j])                    if tmp &gt; max_prob:                        max_prob, last_point = tmp, j                prob_pos.append(max_prob)                path_point.append(last_point)            dp[t], path[t] = prob_pos, path_point        # 回溯        prob_list = list(dp[len(sentence) - 1])        cur_pos = self.poslist[prob_list.index(max(prob_list))]        path_que = []        path_que.append(cur_pos)        for i in range(len(sentence) - 1, 0, -1):            cur_pos = path[i].loc[cur_pos]            path_que.append(cur_pos)        # 返回结果        postag = []        for i in range(len(sentence)):            postag.append(sentence[i] + &#39;/&#39; + path_que[-i - 1])        return postagif __name__ == &quot;__main__&quot;:    # data_clean()    hmm = HmmPosTag()    hmm.train(&quot;./data/PeopleDaily_clean.txt&quot;)    hmm.predict(&quot;在 这 一 年 中 ， 中国 的 改革 开放 和 现代化 建设 继续 向前 迈进  再次 获得 好 的 收成 &quot;)# 1. 语料库中有 26 个基本词类标记#       形容词a、区别词b、连词c、副词d、叹词e、方位词f、语素g、前接成分h、成语i、#       简称j、后接成分k、习惯用语l、数词m、名词n、拟声词o、介词p、量词q、代词r、#       处所词s、时间词t、助词u、动词v、标点符号w、非语素字x、语气词y、状态词z、### 2. 语料库中还有 74 个扩充标记：对于语素，具体区分为 Ag Bg Dg Mg Ng Rg Tg Vg Yg### 3. 词性标注只标注基本词性，因此在数据清洗的过程中，将扩充标记归类到各个基本词类中，语素也归类到相应词类中</code></pre><h2 id="5、实验结果评估"><a href="#5、实验结果评估" class="headerlink" title="5、实验结果评估"></a>5、实验结果评估</h2><p>采用1998年人民日报语料库进行评估，分别用以上算法实现分词、词性标注。评价指标包括精确率precision、召回率recall、F1分数、算法效率。</p><p>（1）  对分词模型进行评估</p><p>选取语料库中的6000行数据进行评估，运行结果如下图：<br><img src="https://img-blog.csdnimg.cn/20210218143506925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210218143506925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"><br>由评估结果可知，最大概率分词模型效果最优，相较于最短路径模型有3% 的提升；Hmm 模型运行效率远低于其他两个模型，且效果不佳。</p><p>（2）  对词性标注模型进行评估</p><p>选取语料库中的2000行数据进行评估，运行结果如下图：<br><img src="https://img-blog.csdnimg.cn/2021021814353571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/2021021814353571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"><br>运行结果第一项是对标准分词结果进行词性标注，运行结果第二项是对最大概率分词模型的预测结果进行分词（只有当词语被正确划分出并且词性标注争取时才会被标记为预测正确）</p><h2 id="6、问题及解决方法"><a href="#6、问题及解决方法" class="headerlink" title="6、问题及解决方法"></a>6、问题及解决方法</h2><ol><li> 问题：Hmm 模型中，大部分词语的发射概率较低，随着句子长度的增加（约为120词），路径的概率变得很小，程序下溢。路径概率取对数，概率相乘转化为对数相加，避免路径概率下溢</li><li>对于 Hmm 模型中出现的未登录词（字）采用 Laplace 平滑处理。由于某些字、词出现很少，如果采用加一平滑会导致发射概率过大的问题，因此采用较小的 λ = 1e-6</li><li> 预料库将人名的姓和名拆分成两个词，将组合的实体名也有拆分，在数据清洗时，我将这两类进行了合并。λ</li></ol>]]></content>
      
      
      <categories>
          
          <category> nlp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++手撕车道线检测</title>
      <link href="/2021021745777/"/>
      <url>/2021021745777/</url>
      
        <content type="html"><![CDATA[<p>运用数字图像处理的基本方法，如边缘提取、hough变换、空域滤波等，在 tuSimple Lane Dataset 上实现车道线检测（图像的输入输出调用OpenCV）</p><span id="more"></span><p>完整代码及车道线数据链接：<br>github：<a href="https://github.com/xuzf-git/lane_detection_by_DIP">https://github.com/xuzf-git/lane_detection_by_DIP</a><br>欢迎来 star &amp;&amp; fork &amp;&amp; issue ~~</p><h2 id="1、主要内容"><a href="#1、主要内容" class="headerlink" title="1、主要内容"></a>1、主要内容</h2><p>使用数字图像处理的基本方法，构建一个车道线检测模型。该模型可以识别图像中所有的车道线，并得到完整的车道线信息。模型在tuSimple Lane Dataset大小为100的数据子集进行了测试，达到了较好的结果。本文专注于体会和理解数字图像处理中的基本算法，因此除图像的读入和展示使用OpenCV外，算法均由C++标准库实现。<br><img src="https://img-blog.csdnimg.cn/20210416132921312.gif#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210416132921312.gif#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"></p><h2 id="2、实现思路"><a href="#2、实现思路" class="headerlink" title="2、实现思路"></a>2、实现思路</h2><p>实现车道线检测，主要包含两部分操作</p><ol><li>道路图像的处理，主要包括灰度图转换、基于高斯平滑的图像去噪、基于Canny算法的边缘提取</li><li>车道线检测方法，主要包括获取感兴趣区域（ROI）、形态学闭运算、基于Hough变换的直线检测</li></ol><p>模型的处理流程如下：<br><img src="https://img-blog.csdnimg.cn/20210217155524396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217155524396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="实现流程"></p><h3 id="2-1-道路图像处理"><a href="#2-1-道路图像处理" class="headerlink" title="2.1 道路图像处理"></a>2.1 道路图像处理</h3><p>通过对道路图像进行处理，突出图像中的车道线部分。模型将彩色图像转化成灰度图像进行处理，目的是简化模型的复杂度，提高运行效率。</p><h4 id="2-1-1-高斯平滑"><a href="#2-1-1-高斯平滑" class="headerlink" title="2.1.1 高斯平滑"></a>2.1.1 高斯平滑</h4><p>由于光照、路面情况、拍摄质量等问题，道路图像上存在很多噪声，通过高斯滤波使图像变得平滑，减弱图像中的噪声对结果的影响，提高车道线检测模型的鲁棒性。</p><p>高斯平滑就是使用高斯滤波器与原图像进行卷积，得到平滑图像。与均值滤波类似，它们都是取滤波器窗口内像素的加权均值作为输出。高斯滤波器的权值分布满足二维高斯函数。  $h(x,y)=e^{- \frac{x^2 + y^2}{2 \sigma ^2}}$ 由于高斯平滑是线性离散滤波，因此离散形式的高斯滤波器为  $H_{i,j} = \frac{1}{2\pi\sigma^2}e^{\frac{(i - k -1)^2 + (j - k - 1)^2}{2\sigma^2}}$</p><p>本实验采用 $3\times3$ 的高斯滤波器。具体实现为定义 <code>Kernel</code> 类实现通用的卷积操作，定义派生类 <code>GaussianKernel</code> 实现不同 size 和 $\sigma$ 高斯滤波器的构建的运算，实现接口如下：</p><pre><code class="c">/* Kernel.h */class Kernel&#123;public:    double **data;    int size;    Kernel(int size);   // 空的卷积核    Kernel(Kernel &amp;cp); // 拷贝构造函数    ~Kernel();    double *operator[](const int idx) const;    // 卷积操作    template&lt;typename T1, typename T2&gt;    void convolve(const Img&lt;T1&gt; &amp;src, Img&lt;T2&gt; &amp;dst, const bool is_clip = true) const;&#125;;class GaussianKernel : public Kernel&#123;public:    double sigma;    GaussianKernel(const int size, const double sigma);    GaussianKernel(GaussianKernel &amp;cp);&#125;;</code></pre><h4 id="2-1-2-边缘提取"><a href="#2-1-2-边缘提取" class="headerlink" title="2.1.2 边缘提取"></a>2.1.2 边缘提取</h4><p>在实验过程中，我曾尝试采用以下方法进行边缘提取的方法。由于在图像中车道线的灰度值较大，因此我设计了一种参数自适应的阈值分割算法，把车道线从图像中抽取出来。具体方法如下：统计图像的灰度分布，选取整体灰度分布相应比例对应的灰度值作为阈值，对图像进行二值化。效果如下：</p><p><img src="https://img-blog.csdnimg.cn/20210217155654580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217155654580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="阈值分割"><br>可以发现，通过阈值分割有效的过滤掉了大部分背景，如山脉、路面、车辆，这为下面的直线检测去除了一定的干扰。但是由于部分图像存在反光或较亮区域，这导致一些车道线丢失，或特征不再明显，如下图。<br><img src="https://img-blog.csdnimg.cn/20210217155720967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217155720967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="阈值分割导致车道线信息丢失"><br>虽然可以通过求图像梯度的方法将大面积的高亮度区域滤除，但是直接将原图转成二值图像处理，会丢失车道线的细节信息导致结果车道线信息不完整。因此舍弃该方案。</p><p>最终采用基于图像梯度的边缘提取方法——Canny算法。Canny主要包含三个步骤：</p><ol><li>Sobel算子：计算图像梯度</li><li>非极大值抑制：去除非边缘的噪点，细化边缘</li><li>双阈值：检测并连接边缘</li></ol><p>（1）Sobel 算子计算图像梯度</p><p>灰度图可以看做灰度值 $h(x,y)$ 关于 $(x,y)$ 坐标的二元函数，计算图像梯度可以通过Sobel算子计算得到。​</p><ul><li>$x$ 方向梯度： ${grad}_x(x,y) = \frac{\partial h(x,y)}{\partial x}$</li><li>$y$ 方向梯度： ${grad}_y(x,y) = \frac{\partial h(x,y)}{\partial x}$</li><li>梯度幅度： $grad = \sqrt{ {grad_x}^2 + {gard_y}^2}$</li><li>梯度方向：$gard_\theta = arctan(\frac{grad_y}{grad_x})$</li></ul><p>其中计算 $x,y$ 方向的梯度使用Sobel算子对图像进行卷积<br>$$<br>grad_x = \begin{bmatrix} -1 &amp; 0 &amp; 1 \ -2 &amp; 0 &amp; 2 \ -1 &amp; 0 &amp; 1 \end{bmatrix} \times img \quad grad_y = \begin{bmatrix} 1 &amp; 2 &amp; 1 \ 0 &amp; 0 &amp; 0 \ -1 &amp; -2 &amp; -1 \end{bmatrix} \times img<br>$$<br>Sobel 算子计算梯度效果如下：<br><img src="https://img-blog.csdnimg.cn/20210217155939174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217155939174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="Sobel算子效果"></p><pre><code class="cpp">/* Sobel 算子：计算图像梯度 */void Sobel(const Img&lt;uchar&gt; &amp;src, Img&lt;uchar&gt; &amp;dst, Img&lt;double&gt; &amp;theta)&#123;    assert(src.rows == dst.rows);    assert(src.cols == dst.cols);    const double sobelX_arr[3][3] = &#123;            &#123;-1, 0, 1&#125;,            &#123;-2, 0, 2&#125;,            &#123;-1, 0, 1&#125;    &#125;;    const double sobelY_arr[3][3] = &#123;            &#123;1,  2,  1&#125;,            &#123;0,  0,  0&#125;,            &#123;-1, -2, -1&#125;    &#125;;    Kernel sobelX(3);    Kernel sobelY(3);    for (int i = 0; i &lt; 3; ++i)    &#123;        for (int j = 0; j &lt; 3; ++j)        &#123;            sobelX[i][j] = sobelX_arr[i][j];            sobelY[i][j] = sobelY_arr[i][j];        &#125;    &#125;    Img&lt;double&gt; imgGradX(src.rows, src.cols);    Img&lt;double&gt; imgGradY(src.rows, src.cols);    sobelX.convolve(src, imgGradX, false);    sobelY.convolve(src, imgGradY, false);    for (int i = 0; i &lt; src.rows; ++i)    &#123;        for (int j = 0; j &lt; src.cols; ++j)        &#123;            dst[i][j] = sqrt(imgGradX[i][j] * imgGradX[i][j] + imgGradY[i][j] * imgGradY[i][j]);            if (fabs(imgGradX[i][j]) &lt; 1e-10)   // 防止除以0，导致溢出                imgGradX[i][j] = 1e-10;            theta[i][j] = atan((double) imgGradY[i][j] / imgGradX[i][j]);        &#125;    &#125;&#125;</code></pre><p>（2）非极大值抑制</p><p>分析上图发现，由于图像灰度存在起伏，所以有一些不是边缘的区域也存在较大的梯度。采用非极大值抑制（NMS）的方法，消除梯度图像中非边缘的噪声，并将边缘细化。</p><p>NMS实现的思路如下：计算每个中心像素点沿梯度方向邻域内各点的梯度值，如果该中心像素点的梯度值是以上像素点梯度值的局部极大值，则保留梯度，否则梯度置为零。由于邻域内在梯度方向上的点不一定是在整数坐标位置，因此需要通过插值计算邻域内梯度方向点的梯度值。实现效果如下：<br><img src="https://img-blog.csdnimg.cn/20210217160027909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217160027909.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="非极大值抑制"><br>一些非边缘的噪点得到了一定程度的抑制，边缘也得到细化。<br>关于Canny边缘检测中非极大值抑制原理的详细说明，可以参考博客 <a href="https://blog.csdn.net/kezunhai/article/details/11620357">Canny算子中的非极大值抑制（Non-Maximum Suppression）分析</a></p><pre><code class="cpp">/* 非极大值抑制 */void NonMaxSuppression(const Img&lt;uchar&gt; &amp;src, Img&lt;uchar&gt; &amp;dst, const Img&lt;double&gt; &amp;theta)&#123;    assert(src.rows == dst.rows);    assert(src.cols == dst.cols);    // 将 src 的值拷贝到 dst 中    dst = src;    uchar local[3][3];    uchar temp1, temp2;    double weight;    const double PI_2 = PI / 2;    const double PI_4 = PI / 4;    for (int i = 1; i &lt; src.rows - 1; ++i)    &#123;        for (int j = 1; j &lt; src.cols - 1; ++j)        &#123;            // 记录考察点的局部值            for (int x = 0; x &lt; 3; ++x)            &#123;                for (int y = 0; y &lt; 3; ++y)                &#123;                    local[x][y] = src[i - 1 + x][j - 1 + y];                &#125;            &#125;            if (theta[i][j] &gt; -PI_2 &amp;&amp; theta[i][j] &lt;= -PI_4)            &#123;                weight = fabs(1 / tan(theta[i][j]));                temp1 = uchar(weight * local[2][2] + (1 - weight) * local[2][1]);                temp2 = uchar(weight * local[0][0] + (1 - weight) * local[0][1]);                if (local[1][1] &lt;= temp1 || local[1][1] &lt;= temp2)                    dst[i][j] = 0;            &#125; else if (theta[i][j] &gt; -PI_4 &amp;&amp; theta[i][j] &lt;= 0)            &#123;                weight = fabs(tan(theta[i][j]));                temp1 = uchar(weight * local[2][2] + (1 - weight) * local[1][2]);                temp2 = uchar(weight * local[0][0] + (1 - weight) * local[1][0]);                if (local[1][1] &lt;= temp1 || local[1][1] &lt;= temp2)                    dst[i][j] = 0;            &#125; else if (theta[i][j] &gt; 0 &amp;&amp; theta[i][j] &lt;= PI_4)            &#123;                weight = tan(theta[i][j]);                temp1 = uchar(weight * local[0][2] + (1 - weight) * local[1][2]);                temp2 = uchar(weight * local[2][0] + (1 - weight) * local[1][0]);                if (local[1][1] &lt;= temp1 || local[1][1] &lt;= temp2)                    dst[i][j] = 0;            &#125; else if (theta[i][j] &gt; PI_4 &amp;&amp; theta[i][j] &lt; PI_2)            &#123;                weight = 1 / tan(theta[i][j]);                temp1 = uchar(weight * local[0][2] + (1 - weight) * local[0][1]);                temp2 = uchar(weight * local[2][0] + (1 - weight) * local[2][1]);                if (local[1][1] &lt;= temp1 || local[1][1] &lt;= temp2)                    dst[i][j] = 0;            &#125;        &#125;    &#125;&#125;</code></pre><p>（3）双阈值检测和边缘连接</p><p>需要将得到的梯度图像进行阈值分割，得到二值图以便后续进行hough变换。采用双阈值对图像进行阈值分割，实现思路如下：</p><ul><li>当梯度值大于高阈值时，将其灰度值取为255。</li><li>当梯度值小于低阈值时，将其灰度值取为0。</li><li>当梯度介于两者之间是，如果该点邻域内有高阈值点，则取为255，否则取0。</li></ul><p>双阈值处理中，高阈值将物体边缘和背景区分开，但是当高阈值较大时，可能导致边缘断断续续；此时低阈值平滑边缘轮廓，能实现较好的分割效果。同时借鉴之前尝试对灰度图做阈值分割的思路，采用整体灰度分布相应比例处的灰度值为高阈值，低阈值取高阈值的 $\frac{2}{3}$，实现效果如下：<br><img src="https://img-blog.csdnimg.cn/20210217160103365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217160103365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="Canny 边缘提取结果"></p><pre><code class="cpp">/* 双阈值检测 &amp; 连接边缘 */void DoubleThreshold(Img&lt;uchar&gt; &amp;image, const double weight)&#123;    double highThreshold;    double lowThreshold;    bool flag = false;    std::vector&lt;uchar&gt; vec;    // 高阈值取灰度分布图中 weight 对应的灰度值    for (int i = 0; i &lt; image.rows; ++i)    &#123;        for (int j = 0; j &lt; image.cols; ++j)            vec.push_back(image[i][j]);    &#125;    std::sort(vec.begin(), vec.end());    highThreshold = vec[weight * image.rows * image.cols];    // 低阈值为高阈值的 2/3    lowThreshold = highThreshold / 1.5;    for (int i = 1; i &lt; image.rows - 1; ++i)    &#123;        for (int j = 1; j &lt; image.cols - 1; ++j)        &#123;            if (image[i][j] &lt; lowThreshold) // 检测低阈值                image[i][j] = 0;            else if (image[i][j] &gt; highThreshold) // 检测高阈值                image[i][j] = 255;            else // 介于双阈值之间，连接边缘            &#123;                // 检查邻域中是否有高于阈值点（排除孤立的局部极大值点)                for (int x = -1; x &lt; 2; ++x)                &#123;                    if (flag) break;                    for (int y = -1; y &lt; 2; ++y)                    &#123;                        if (image[i + x][j + y] &gt; highThreshold)                        &#123;                            image[i][j] = 255;                            flag = true;                            break;                        &#125;                    &#125;                &#125;                if (!flag)                    image[i][j] = 0;            &#125;        &#125;    &#125;&#125;</code></pre><h3 id="2-2-车道线检测"><a href="#2-2-车道线检测" class="headerlink" title="2.2 车道线检测"></a>2.2 车道线检测</h3><h4 id="2-2-1-梯形-ROI-mask"><a href="#2-2-1-梯形-ROI-mask" class="headerlink" title="2.2.1 梯形 ROI mask"></a>2.2.1 梯形 ROI mask</h4><p>经过图像的边缘提取，车道线边缘已经从图像中抽取出来。观察边缘图像发现：道路两边的环境复杂，存在很多干扰车道线检测的直线边缘，如天际线、山脉边缘、电线杆、树丛等。同时考虑到道路图像中，车道线集中在图像的中间偏下区域，因此可以仅对感兴趣区域(ROI)进行处理和检测。根据车道线图像特点，采用梯形掩码获取ROI。</p><p>观察图像选取了(400, 0) (220, 420) (200, 860), (400, 1280)四个点作为 mask 的角点。mask图像如下<br><img src="https://img-blog.csdnimg.cn/2021021716014062.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/2021021716014062.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="梯形 mask"><br>ROI 效果如下：<br><img src="https://img-blog.csdnimg.cn/20210217160216811.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217160216811.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="感兴趣区域"></p><pre><code class="cpp">/* 遮盖无效部分 */void RoiMask(Img&lt;uchar&gt; &amp;src)&#123;    // 梯形 ROI 区域进行 mask (400, 0) (220, 420) (200, 860), (400, 1280)    for (int i = 0; i &lt; src.rows; ++i)    &#123;        for (int j = 0; j &lt; src.cols; ++j)        &#123;            if (i &lt;= 200)                src[i][j] = 0;            else if (i &gt; 400)                continue;            else if (2.1 * (400 - i) &gt; j || j &gt; 1280 - 2.1 * (400 - i))                src[i][j] = 0;        &#125;    &#125;&#125;</code></pre><h4 id="2-2-2-hough-变换检测直线"><a href="#2-2-2-hough-变换检测直线" class="headerlink" title="2.2.2 hough 变换检测直线"></a>2.2.2 hough 变换检测直线</h4><p>hough变换是一种目标检测的方法，可以检测出有明确表达式的图形。hough 变换的基本原理：利用两个不同坐标系之间的变换来检测图像中的直线。将图像空间中的直线映射到参数空间的一个点，然后对参数空间中的点进行累计投票，进而得到参数空间中的峰值点，该峰值点就对应空间坐标系中的真实存在的直线参数。</p><p>hough变换中，直线采用极坐标方程表示，因为参数$\theta$ 和 $r$ 的范围有限，便于以相同步长进行离散化</p><p>实现思路：</p><ul><li>初始化参数空间（二维矩阵）</li><li>遍历空间坐标系的每个非零像素点，为所有可能经过该点的直线的参数进行投票。</li><li>找出参数空间中大于指定阈值的参数点</li></ul><p>hough 变换效果如下图：<br><img src="https://img-blog.csdnimg.cn/20210217160247882.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217160247882.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="hough变换"><br>hough变换的原理可以参考博客 <a href="https://blog.csdn.net/saltriver/article/details/80547245">Hough直线检测的理解</a><br>由于车道线存在一定的弧度并非严格地直线，且存在一定宽度，导致每条车道线都会检测出多条对应直线。可以采用聚类的方法对检测出的直线进行聚类，以得到更精准的效果。</p><pre><code class="cpp">void HoughTransform(Img&lt;uchar&gt; &amp;src, vector&lt;pair&lt;int, int&gt;&gt; &amp;lines, int threshold)&#123;    // 参数空间的计数矩阵    int **count;    // 计数器初始化    int rows = src.rows;    int cols = src.cols;    int r_max = 2 * (int) sqrt(rows * rows + cols * cols) + 1;    count = new int *[181];    for (int i = 0; i &lt; 181; ++i)    &#123;        count[i] = new int[r_max];        memset(count[i], 0, r_max * sizeof(int));    &#125;    // 参数空间变量    int theta, r;    // 遍历图像为每组参数投票    for (int row = 0; row &lt; rows - 2; ++row)    &#123;        for (int col = 2; col &lt; cols - 2; ++col)        &#123;            // 对边缘点进行统计            if (src[row][col] == 255)            &#123;                for (theta = 0; theta &lt; 181; ++theta)                &#123;                    r = int(row * sin(theta * PI / 180.0) + col * cos(theta * PI / 180.0) + r_max / 2.0);                    count[theta][r]++;                &#125;            &#125;        &#125;    &#125;    // 遍历计数矩阵，选出超出阈值的参数    for (theta = 0; theta &lt; 181; ++theta)    &#123;        for (r = 0; r &lt; r_max; ++r)        &#123;            if (count[theta][r] &gt;= threshold &amp;&amp; abs(theta - 90) &gt;= 15 &amp;&amp; abs(theta) &gt; 10 &amp;&amp; 180 - theta &gt; 10)                // if (count[theta][r] &gt;= threshold)            &#123;                if (theta &gt; 90 &amp;&amp; (r - r_max / 2) &lt; 0)                    lines.emplace_back(theta - 180, r_max / 2 - r);                else                    lines.emplace_back(theta, r - r_max / 2);            &#125;        &#125;    &#125;    // 直线参数聚类    lines_cluster(lines);    for (int i = 0; i &lt; 181; ++i)    &#123;        delete[] count[i];    &#125;    delete[] count;&#125;</code></pre><h4 id="2-2-3-车道线聚类"><a href="#2-2-3-车道线聚类" class="headerlink" title="2.2.3 车道线聚类"></a>2.2.3 车道线聚类</h4><p>由于 k-means 等聚类算法复杂度较高，影响车道线检测的实时性。所以我设计了一种高效的聚类方案。具体思路如下：根据以两个直线的角度参数距离为相似度函数，遍历hough变换检测出的所有直线参数，如果相似度高于阈值，则认为属于同一类别，该类别大小加一；如果相似度低于阈值，则认为属于不同类别，与下一个类中心点进行比较。如果没有相似的</p><p>伪代码如下：</p><pre><code class="c">params;     // hough 变换得到参数列表clusters;     // 聚类列表flag;         // 标记是否新建类for param in params&#123;    flag = true;    for cluster in clusters    &#123;        if is_similar(param, cluster)    // 如果相似则添加到该类中        &#123;            flag = false;            update(cluster);            break;        &#125;    &#125;    if flag    // 与现有的所有类都不同        clusters.append(param);    // 添加新类&#125;</code></pre><p>这里相似度函数采用两条直线的角度参数的差值。</p><p>一开始选择的更新聚类中心的方法，是取同一类别的平均值，效果不佳。经过尝试最后采用取每个类别的初始值为中心点，实现较好的效果。示例如下：<br><img src="https://img-blog.csdnimg.cn/20210217160336316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217160336316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="聚类中心点对比"><br>评测结果对比：</p><table><thead><tr><th>中心点</th><th>Accuracy</th><th>FP</th><th>FN</th></tr></thead><tbody><tr><td>数据均值</td><td>0.5740</td><td>0.7058</td><td>0.7533</td></tr><tr><td>聚类初始值</td><td>0.7539</td><td>0.5025</td><td>0.5242</td></tr></tbody></table><p><em><strong>分析原因</strong></em>：由于车道线有一定弧度，导致前半部分和后半部分的车道线参数差距较大。如果降低判定相似的标准，就会导致本不相似的直线求均值，从而使Accuracy较低；如果提高相似的标准就会，导致聚类得到类别很多，从而FP较大；因此采用加权均值更新聚类中心点并不理想。</p><p>按照车道线聚类结果中每个类别的大小，对聚类结果进行排序，选择所有聚类结果中规模最大的4个类作为最终确定的直线参数。</p><p>代码接口如下：</p><pre><code class="c">// 相似函数bool is_similar(pair&lt;int, int&gt; &amp;l1, pair&lt;int, int&gt; &amp;l2);// 更新类中心点void update_cluster(pair&lt;int, int&gt; &amp;line, pair&lt;pair&lt;int, int&gt;, int&gt; &amp;cluster);// 直线聚类void lines_cluster(vector&lt;pair&lt;int, int&gt;&gt; &amp;lines);// hough变换void HoughTransform(Img&lt;uchar&gt; &amp;src, vector&lt;pair&lt;int, int&gt;&gt; &amp;lines, int threshold);</code></pre><h3 id="2-3-输出结果"><a href="#2-3-输出结果" class="headerlink" title="2.3 输出结果"></a>2.3 输出结果</h3><p>函数接口如下：</p><pre><code class="c">/* 根据车道线的参数，获取坐标向量 */void GetLanes(Img&lt;uchar&gt; &amp;src, vector&lt;pair&lt;int, int&gt;&gt; &amp;params, vector&lt;vector&lt;int&gt;&gt; &amp;lanes);/* 将检测结果写入json文件 */void WriteJson(string &amp;raw_file, vector&lt;vector&lt;int&gt;&gt; &amp;lanes, double run_time, ofstream &amp;of);/* 展示车道线检测结果 */void polyLanes(const string &amp;path, vector&lt;vector&lt;int&gt;&gt; &amp;lanes, int delay);</code></pre><p>通过 <code>GetLanes</code> 将每个直线参数转换成直线坐标，<code>WriteJson</code> 函数将结果写入json文件，<code>polyLanes</code> 可视化展示车道线。</p><p>实现效果如下：<br><img src="https://img-blog.csdnimg.cn/20210217160438522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20210217160438522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="检测结果"></p><h2 id="3、-数据结构"><a href="#3、-数据结构" class="headerlink" title="3、 数据结构"></a>3、 数据结构</h2><p>由于只允许使用OpenCV进行图像的读写操作，因此本实验构建了 <code>Img</code> 模板类，作为图像存储和操作的基本数据结构，代码接口如下：</p><pre><code class="c">template&lt;typename T&gt;class Img&#123;public:    T **data;   // 存放数据    int rows;   // 图像的行数    int cols;   // 图像的列数    Img(int rows, int cols); /* 构造空值图像 */    Img(const char *path);   /* 读入图像：灰度图 */    Img(Img &amp;cp);            /* Img类的复制构造函数 */    ~Img();    T *operator[](const int idx) const;    Img &amp;operator=(const Img &amp;cp);    cv::Mat toMat() const;                        /* 将图像转换成 cv::Mat */    void show(const char *name, int delay) const; /* 展示图片 */&#125;;</code></pre><p>展示图片的<code>plotLanes</code>函数也使用了 OpenCV 框架对图像进行展示。</p><h2 id="4、-实现效果"><a href="#4、-实现效果" class="headerlink" title="4、 实现效果"></a>4、 实现效果</h2><p>经过运行 TuSimple Lane Detection 项目的测评脚本，得到在数据子集上检测结果如下：</p><table><thead><tr><th>Accuracy</th><th>FP</th><th>FN</th></tr></thead><tbody><tr><td>0.7539</td><td>0.5025</td><td>0.5242</td></tr></tbody></table><p>实现了较好的测评效果。检测每张图像约用时0.4秒。</p><h2 id="5、-总结及改进"><a href="#5、-总结及改进" class="headerlink" title="5、 总结及改进"></a>5、 总结及改进</h2><p>实现过程中尝试了很多方案，如采用形态学运算，提高车道线的完整性；通过阈值分割，去除背景和干扰物；采用均值作为聚类中心等。由于方案设计上的主观缺陷和检测任务的存在的光照不均、环境复杂等客观因素，以上方案均被舍弃。最终经过实践得到了一种鲁棒性较好，效果较优的车道线检测方案。</p><p>查阅相关资料，了解到可以通过最大类间方差法(OTSU)进行阈值分割、动态ROI区域等。可以通过以上算法进一步提高模型精度和性能。</p>]]></content>
      
      
      <categories>
          
          <category> cv </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> cv </tag>
            
            <tag> dip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning Human Pose Estimation Features with Convolutional Networks</title>
      <link href="/2020090727273/"/>
      <url>/2020090727273/</url>
      
        <content type="html"><![CDATA[<p>作者介绍了一种使用多层卷积网络结构的人体姿势估计模型，以及可学习低层特征和高层弱空间模型的改进的学习方法。</p><span id="more"></span><h3 id="ICLR-2014"><a href="#ICLR-2014" class="headerlink" title="ICLR 2014"></a>ICLR 2014</h3><p><a href="https://arxiv.org/abs/1312.7302">arXiv 原文链接</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>作者介绍了一种使用多层卷积网络结构的人体姿势估计模型，以及可学习低层特征和高层弱空间模型的改进的学习方法。</p><p>文章主要贡献：</p><ul><li>首次展示深度学习模型能很好地完成无约束的姿态估计任务。</li><li>发现在仅覆盖图像上几个像素的区域上就可以学习强大的低级特征检测器</li><li>作者以 bottom-up 模型和弱空间模型超过了当时最佳模型</li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>高自由度的人体人体姿态是 CV 领域最复杂的任务之一，尤其是不使用启发式模型对单个图像进行事先假设，而直接在复杂背景中定位人体关键部位占据的很小的几个像素点。</p><ul><li>之前表现最好的姿态估计方法（DPM）通常基于<strong>身体部位检测器</strong>：包含多个步骤<ol><li>提取图像的低级特征：SIFT、HoG etc 获取局部 patch 的统计信息</li><li>将低级特征整合到局部空间域</li><li>将聚合特征映射成向量，传入具体任务中</li></ol></li><li>深度学习方法：该方法在一般的物体识别任务中得到认可，但在姿态估计中面临挑战，包括：身体的非刚性结构、精度不足、姿势的复杂多峰的性质。</li></ul><p>作者基于卷积网络提出的人体姿态估计的 end-to-end 模型，使得卷积网络能在姿态估计领域起作用。作者提出了一种两阶段的特征检测 pipeline</p><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2 Related Work"></a>2 Related Work</h2><ul><li> sliding-window 局部检测器</li><li> “bag of features” + regression /  SVM /  nearest neighbo</li><li> 局部检测 + 结构推理</li><li> 图形结构（姿态、parts-based 模型）</li></ul><h2 id="3-Model"><a href="#3-Model" class="headerlink" title="3 Model"></a>3 Model</h2><p>用卷积网络做姿势估计，最明显的方法是将图像输入直接映射到关节姿势的编码向量。 卷积输出关节的位置，或者表示关节角度的层次结构。 但作者发现该方法效果很差。 一个问题是，池化虽然利于物体识别过程中的平移不变性，但会破坏精确预测姿势所必需的精确空间信息。另一个问题是，从输入空间到运动人体姿态编码的直接映射是高度非线性的。即使选择这种直接映射，大多数情况下，网络会将输入映射到无效姿势的空间。</p><p>作者发现训练多个卷积网络以执行独立的身体部位二分类，每个特征使用一个网络能实现更好的效果。这些卷积作为滑动窗口应用于输入的区域，并将像素窗口映射到单个二进制输出：存在或不存在该身体部位。该网络的最终输出结果是得到一个响应图，表示某个身体部位在该位置的置信度。再由检测出的关键部位位置推理出人体姿势。</p><h3 id="3-1-Convolutional-Network-Architecture"><a href="#3-1-Convolutional-Network-Architecture" class="headerlink" title="3.1 Convolutional Network Architecture"></a>3.1 Convolutional Network Architecture</h3><p>作者的两阶段的特征检测 pipeline 模型基于标准的卷积神经网络结构，如下图：</p><p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传<br><img src="https://img-blog.csdnimg.cn/20200907200908430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20200907200908430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNTg2MDQz,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="在这里插入图片描述"></p><p>图片首先进行了局部对比归一化（LCN）以强调。。</p><p><strong>卷积模型结构</strong>：</p><ul><li>局部对比归一化（LCN）：增强几何的不连续性并提高泛化性能</li><li>三个卷积和二次采样层处理，这三个层使用 ReLU 激活和 MaxPool <ul><li>MaxPool 仅使用 2×2 池化的两个阶段（其中总图像下采样率为4×4）</li></ul></li><li>将最后的池化图展平为一个向量，并由三个全连接的层进行处理</li></ul><p><strong>卷积网络训练</strong>：</p><p>作者使用批量随机梯度下降。 并预留了一个验证集来调整网络的超参数，例如特征的数量和大小，学习率，动量系数等。作者使用 Nesterov 动量和 RMSPROP 来加速学习。并且作者在每个全连接层的输入上使用了 L2 正则化和 dropout ，以减弱过拟合</p><h3 id="3-2-Enforcing-Global-Pose-Consistency-with-a-Spatial-Model"><a href="#3-2-Enforcing-Global-Pose-Consistency-with-a-Spatial-Model" class="headerlink" title="3.2 Enforcing Global Pose Consistency with a Spatial Model"></a>3.2 Enforcing Global Pose Consistency with a Spatial Model</h3><p>当模型应用于验证集时，3.1节中介绍的网络的原始输出会产生许多 False-Positives 。作者认为这是由于两个因素造成的：</p><ol><li>作为卷积网络输入的小图像上下文（64×64像素或大约输入图像区域的5％）不能提供足够的模型上下文信息来执行解剖学上一致的关节位置推断</li><li>训练集的大小是有限的。 因此，作者使用具有简单人体姿势的空间模型从 convnet 输出中删除强异常值。 不希望这个模型会提高接近 Ground Truth（例如10像素以内）的姿势的性能，但是它用作后期处理步骤，以消除由于异常离群值而导致的解剖学上不可能的姿势（简而言之： 根据已有的简单人体姿势把模型输出的异常姿势删掉）</li></ol><p>下面就是介绍<strong>如何通过构建先验的人体姿态空间模型过滤预测异常，得到联合分布</strong>：</p><p>简单空间模型中人体关键节点连通性如下图所示：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvWW9JT0Jpc25LSHdTR210LnBuZw?x-oss-process=image/format,png" class="lazyload" data-srcset="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvWW9JT0Jpc25LSHdTR210LnBuZw?x-oss-process=image/format,png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20200823203041901"></p><p>该图抽象地展示人体的单侧关节，作者以脸部，左肩，左肘部，左手腕为例。以图像上的像素位置 $x$ 为随机变量，可得：</p><ul><li><p>卷积网络模型生成脸部，肩膀，肘部和腕关节关于 $x$ 的响应图：$p_{fac}(x)，p_{sho}(x)，p_{elb}(x)，p_{wri}(x)$</p></li><li><p>空间模型生成过滤后的响应图：$\hat{p}<em>{fac}(x)，\hat{p}</em>{sho}(x)，\hat{p}<em>{elb}(x)，\hat{p}</em>{wri}(x)$ <em><strong>（该步骤目标输出）</strong></em></p></li><li><p>两个关节可以组成一对（pairwise）$(a,b)$ ，每个关节 pair 以 b 的位置为图像中心，在训练集上计算身体部位的先验条件概率 $p_{a|b=\vec{0}}(x)$ 得到先验条件分布图， 然后对直方图进行平滑处理（使用 Gaussian 滤波器）并进行归一化。学习到先验条件分布响应图： $p_{sho|fac=\vec 0}(x)，p_{elb|sho=\vec 0}(x)，p_{wri|elb=\vec 0}(x)$ 如下所示：</p></li></ul><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvZ3lsNDFIR0lUY3JhcHhaLnBuZw?x-oss-process=image/format,png" class="lazyload" data-srcset="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvZ3lsNDFIR0lUY3JhcHhaLnBuZw?x-oss-process=image/format,png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20200823214534692"></p><blockquote><p>由于对称性，先验 $p_{sho|fac=\vec 0}(x)$ 是 $p_{fac|sho=\vec 0}(x)$ 的180° 旋转（同其他相邻对）。作者没有像许多 parts-based 检测器中的标准做法那样假设简单的高斯分布来建模相邻节点的 pairwise 关系，而是发现这些非参数空间先验，以提高检测性能。</p></blockquote><p>给定完整的先验条件分布和卷积一元分布后，现在可以使用类似于Sum-Product 置信度传播算法来构造每个部分的过滤分布。对于身体的部位 $i$ ，有一组相邻节点 $U$ ，则最终分布定义为：<br>$$<br>\hat p_{i} \propto p_i^\lambda \ \prod_{u \in U} (p_{i|u} * p_u)<br>$$<br>其中 $\lambda$ 是一个混合参数，并且控制每个关节的一元分布对其最终过滤分布的置信度（作者在实验中使用 $\lambda = 1$）。对数空间中，上述用于肩关节的概率变为<br>$$<br>log(\hat p_{sho}) \propto \lambda ; log(p_{sho})+log(p_{sho|fac=\vec 0} * p_{fac}) + log(p_{sho|elb=\vec0} * p_{elb})<br>$$</p><p>作者还对肘关节和腕关节进行等效计算。面部关节被视为特例。根据经验，作者发现用空间模型过滤对脸部分布会导致性能下降。这可能是由于convnet在定位面部位置方面做得非常好，因此从肩部检测器中获取嘈杂的证据实际上会增加不确定性。取而代之的是，对于脸部，作者使用全局先验分布 $h_{fac}$，这是通过学习训练集图像中人脸位置的位置直方图获得的，如下图所示。对数空间中，人脸的输出分布如下：<br>$$<br>log(\hat p_{fac}) \propto \lambda ; log(p_{fac}) + log(h_{fac})<br>$$<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvRzltczhIaDd3RXpYZllkLnBuZw?x-oss-process=image/format,png" class="lazyload" data-srcset="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvRzltczhIaDd3RXpYZllkLnBuZw?x-oss-process=image/format,png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20200823222702762"></p><p>最后，由于学习到的神经网络的卷积特征和空间先验并没有明确地按比例缩放，因此必须在测试时在多个比例的图像上运行卷积和空间模型，然后使用这些比例上最可能的联合位置作为最终比例联合位置。</p><p>对于包含多人示例的数据集（已知先验），需要使用非最大抑制算法在每个比例的过滤后的响应图中找到多个局部最大值，然后从场景中每个人的最可能联合候选者中选取 top $n$。</p><h2 id="4-Results"><a href="#4-Results" class="headerlink" title="4 Results"></a>4 Results</h2><p>作者在 FLIC 数据集上评估了该模型</p><blockquote><p>FLIC 数据集由从各种好莱坞电影中拍摄的5003张静态RGB图像组成。数据集中的每个帧都包含至少一个正面姿势的人（面对镜头），并且每个帧均由AmazonMechanical Turk处理以获取单个人上半身关节位置的 Ground Truth 标签。 FLIC数据集对于最新的姿势估计方法极具挑战性，因为姿势不受约束，身体部位经常被遮挡，衣服和背景不一致。</p></blockquote><p>作者取用数据集中的3987个图像进行训练，同时将它们水平镜像以获得一个总共3987×2 = 7974个示例。由于训练图像的比例不同，因此作者还手动注释了这些训练集图像中头部的边界框，并将其调整为标准比例。此外，作者将它们裁剪为320×240，以使肩部注释的中心位于（160px，80 px）。作者不会在测试时执行此图像标准化。按照Felzenszwalb等人的方法。在测试时，仅在一个人的图像上运行模型（1016个测试用例中的351个图像）。如第3节所述，该模型在6个不同的输入图像比例尺上运行，然后选用在这些比例尺上具有最高置信度的联合位置作为最终位置</p><p>为了训练卷积网络，作者使用 Theano ，训练时，GPU上缓存100个 batch；该系统具有两个执行的主要线程：</p><ol><li><p>在GPU上运行的训练函数，用于评估批处理的SGD更新； </p></li><li><p>数据分派函数，用于预处理CPU上的数据，并在以下情况下在GPU上传输数据：</p><blockquote><p>线程（1）完成了100个 batch 的处理。在NVIDIA TITAN GPU上训练每个卷积网络每个图块所需的时间为1.9ms（fprop + bprop）=总共41分钟。在具有5000个节点的cpu集群上进行测试。测试耗时：每张图像0.49秒（0.94倍比例尺）=总共2.8分钟NMS和空间模型花费的时间可以忽略不计。</p></blockquote></li></ol><p>在测试时，由于每张图像中所有窗口的权重相同，我们将学习的卷积核与完整图像进行卷积而不是单个窗口。这大大减少了在整个测试集上执行前向传播的时间。</p><h3 id="4-1-Evaluation"><a href="#4-1-Evaluation" class="headerlink" title="4.1 Evaluation"></a>4.1 Evaluation</h3><p>作者使用Sapp等人提出的准确性度量：对于给定的关节精度半径，计算在半径阈值（其中距离定义为二维欧式距离，以像素为单位）内正确的测试集中的关节百分比。 作者评估了在腕部，肘部和肩部关节上的性能指标。还将本文模型与 DPM 和 MODEC 架构进行了比较，在测试所有检测器时，都使用351个图像的相同子集</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvQXY5SHlwWG96V3RsMjdCLnBuZw?x-oss-process=image/format,png" class="lazyload" data-srcset="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pLmxvbGkubmV0LzIwMjAvMDgvMjMvQXY5SHlwWG96V3RsMjdCLnBuZw?x-oss-process=image/format,png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="image-20200823232759390"></p><p>上图表明作者的架构在三个身体部位上的性能均优于或等于MODEC和DPM检测器。对于手腕和肘关节，简单空间模型可改善约5％的测试用例（在5像素阈值下）的关节定位，这使本文模型性能优于所有其他检测器。但是，对于肩关节，空间模型实际上会降低大阈值时的关节定位精度。这可能是由于弯头上的convnet性能不佳。</p><p>不出所料，空间模型无法提高已经接近正确值的点的关节精度，但是在消除腕部和肘关节的异常值方面仍然取得了成功。上图是一个示例，其中在应用空间模型之前，较大的 False-Positive 导致不正确的关节位置，随后在应用空间模型后将其删除。</p><h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5 Conclusion"></a>5 Conclusion</h2><p>作者改进了无约束的人体姿势估计。卷积网络是良好的低级特征检测器，与全局先验分布结合使用时，它们的性能可以胜过更复杂和流行的模型。</p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> paper </tag>
            
            <tag> deeplearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最近点对问题</title>
      <link href="/2020040462198/"/>
      <url>/2020040462198/</url>
      
        <content type="html"><![CDATA[<p>最近点对问题：</p><p>在平面内有点集 S ，S 包含 n 个点。已知每个点的坐标 (x, y) ，求最近的两点之间的距离 (n &gt; 2)。如果存在重合的两个点，最近距离记为0。</p><span id="more"></span><p>枚举的方法时间复杂度是 <strong>O(n^2)</strong> ，通过分治可以将时间复杂度降为 **O(nlog(n))**；</p><h2 id="分治策略"><a href="#分治策略" class="headerlink" title="分治策略"></a>分治策略</h2><p>​    利用一条直线将平面上的所有点集 S 分成两部分S1、S2，分别计算这两部分的最短距离d1、d2，再进行合并。合并时，平面上所有点的最短距离为 dis，则 dis 就是 <strong>d1</strong>、<strong>d2</strong> 和分别在位于S1 和 S2 的两个点对的距离 <strong>d12</strong> 中最小的那个，即：<strong>dis = Closest() = min (d1, d2, d12)</strong>;</p><h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><p>首先需要对将 S 中所有点存放在结构体数组 points[ ] 中（共有 n 个），按照 x 坐标的大小将 points[ ] 从小到大进行排序。其中结构体包含点的 x 坐标和 y 坐标。</p><p>求最近点距 <strong>dis =  Closest(1, n)</strong> ，有划分、递归、合并三个基本步骤。</p><ol><li><p>划分：取排序的中间位置处的一条直线 <strong>mid = l + r</strong>，将平面分成左右两部分S1，S2 如图。</p><p> <img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN/img/closestpoint1.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN/img/closestpoint1.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p></li><li><p>递归：递归调用求最近点距函数 Closest( ) ，分别计算 S1 和 S2 两个点集的最短距 d1 和 d2。<strong>取 d1 和 d2 中较小的那个作为 d 。</strong></p></li><li><p>合并：计算分别位于 S1 和 S2 的两个点之间最小的距离 d12。对于 x &lt; mid - d 或者 x &gt; mid + d 范围内的点，显然不会出现点距小于 d 的情况。因此<strong>只需要在 mid 左右为 d 的范围内寻找最近的点距</strong>。有以下步骤：</p><ol><li>将处于 <strong>mid - d &lt;= x &lt;= mid + d</strong> 范围内的点选出来，存储到 <strong>selected[ ]</strong> 数组中，<strong>selected[ ]</strong> 数组是一个临时数组，用来存放选出来的点的索引。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN/img/closestpoint2.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN/img/closestpoint2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><ol start="2"><li>将 selected[ ] 按照 y 坐标的值从小到大排序。目的是将 y 方向距离比较近的点放在一起。遍历selected[] 数组中的点时，对于每个点最多遍历出现在它下面相邻的 6 个点，因此合并是线性复杂度。</li><li>最终的最小点距 dis = min(d1, d2, d12)</li></ol></li></ol><blockquote><p>”最多遍历6个其他点“ 解释：</p><p>​    对于 selected[ ] 数组中的每个点，<strong>只需要遍历其下方的点</strong>，因为它上方点遍历其他点的时候已经把它们之间的距离计算过了，所以只需要<strong>考虑下方距离为 d ，左右距离也分别为 d 的矩形区域</strong>，如下图。<strong>不妨把 mid 线上的点认为属于S1</strong>，那么由于左侧正方形区域中最近距离为 d1 ( &lt; d )， 所以<strong>左边正方形最多存在1、2、5、6 四个点</strong>，如果有第5个点，那就一定会有该点与某个点的距离小于 d1 与左侧最小距离为 d1 矛盾。除 mid 线上的两个点外（已经算在左侧区域中），<strong>右侧最多包含3、4、7三个点</strong>，其中 7 是分别以3、4为圆心 d2 为半径的圆弧的交点。<strong>所以这个矩形区域内，对于某个遍历到的点，最多计算它与其他6个点之间的距离</strong></p></blockquote><img src="https://i.postimg.cc/bY5Kmp4t/closestpoint3.png" class="lazyload" data-srcset="https://i.postimg.cc/bY5Kmp4t/closestpoint3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="zoom:150%;" /><h2 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><p>递归深度是 log(n) ,每次递归的时间复杂度是 nlog(n)（有排序），所以复杂度是 $$O(n*log(n)*log(n))$$</p><h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><pre><code class="c++">#include &lt;cstdio&gt;#include &lt;math.h&gt;#include &lt;algorithm&gt;#define MAX 100002#define INF 1e30using namespace std;struct Point&#123;    double x, y;&#125; points[MAX];int selected[MAX]; bool cmp1(const Point &amp;a, const Point &amp;b)&#123;    return a.x &lt; b.x;&#125;bool cmp2(const int &amp;a, const int &amp;b)&#123;    return points[a].y &lt; points[b].y;&#125;// 计算两个点之间的距离double len(const int &amp;a, const int &amp;b)&#123;    return sqrt((points[a].x - points[b].x) * (points[a].x - points[b].x) +                 (points[a].y - points[b].y) * (points[a].y - points[b].y));&#125;// 计算最近点距double Closest(int l, int r)&#123;    if (l == r)        return INF;    if (l + 1 == r)        return len(l, r);    double min;    int mid = (l + r) / 2;    /* 计算分隔线同侧点对的最短距离 */    double leng1 = Closest(l, mid);    double leng2 = Closest(mid + 1, r);    leng1 &lt; leng2 ? min = leng1 : min = leng2;    /* 计算分隔线两侧点对的距离 */    int j = 0;    // 找出所有离分隔线的距离小于min的点    for (int i = l; i &lt;= r; i++)    &#123;        if (points[i].x - points[mid].x &gt;= -min &amp;&amp; points[i].x - points[mid].x &lt;= min)        &#123;            selected[j] = i;            j++;        &#125;    &#125;    // 把选出来的点，按照y排序    sort(selected, selected + j, cmp2);    // 对于y方向的相距小于min的点，测量距离，更新min    for (int i = 0; i &lt; j; i++)    &#123;        for (int k = i + 1; k &lt; i + 7; k++) // 最多遍历6个其他点        &#123;            if (points[selected[k]].y - points[selected[i]].y &gt; min)                break;            double temp = len(selected[i], selected[k]);            if (temp &lt; min)                min = temp;        &#125;    &#125;    return min;&#125;int main(int argc, char const *argv[])&#123;    int n;    while (true)    &#123;        scanf(&quot;%d&quot;, &amp;n);        if (n == 0)            break;        for (int i = 0; i &lt; n; i++)        &#123;            scanf(&quot;%lf %lf&quot;, &amp;points[i].x, &amp;points[i].y);        &#125;        sort(points, points + n, cmp1);        printf(&quot;%.2lf\n&quot;, Closest(0, n - 1));    &#125;    return 0;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性时间选择算法</title>
      <link href="/202003233/"/>
      <url>/202003233/</url>
      
        <content type="html"><![CDATA[<p>元素选择问题：给定一个能够线性排序的集合（该集合中有 n 个元素）和 一个整数 k（1 $$\le$$ k $\le$ n） ，找出这 n 个元素中第 k 小的元素。</p><span id="more"></span><p>顾名思义，“线性时间选择”就是“选择问题”的“线性时间”算法。</p><h2 id="1-选择问题"><a href="#1-选择问题" class="headerlink" title="1. 选择问题"></a>1. 选择问题</h2><blockquote><p>元素选择问题：给定一个能够线性排序的集合（该集合中有 n 个元素）和 一个整数 k（1 $$\le$$ k $\le$ n） ，找出这 n 个元素中第 k 小的元素。</p></blockquote><p>时间下界：</p><ul><li><p>当 $$k = 1 或 k = n$$时，时间复杂度为 $O(n)$</p></li><li><p>当 $k \le n/log(n) 或 k \ge n - n/log(n)时$，时间复杂度为$O(n + klog(n)) = O(n)$（堆排序）</p></li></ul><h2 id="2-解决方法"><a href="#2-解决方法" class="headerlink" title="2. 解决方法"></a>2. 解决方法</h2><p><strong>方法一</strong>：先排序，再找第 k 小的数。$O(n)$时间</p><p><strong>方法二</strong>：随机选择算法：使用快速排序方法, 最多对一段继续分解 最坏时间$O(n^2)$, 平均时间$O(n)$ </p><ol><li><p>RamdomizedPartition(a, p, r) 快排中的分解算法</p><ol><li><p>i=Ramdom(p,r)    //在p:r中随机选择一个数i </p></li><li><p>交换 a[i] 与 a[p]   //将a[i]换到左端点</p></li><li><p>执行Partition(a,p,r)</p></li></ol><pre><code class="c">RamdomizedPartition(a, p, r)     //排序a[p:r] &#123;         i = Ramdom(p, r);     swap(a[i], a[p]);    return Partition(a, p, r);&#125;</code></pre></li><li><p>RandomSelect(a, p, r)</p><pre><code class="c">RSelect(a,p,r,k)      //选择a[p:r]中第k小数&#123;      if (p == r)        return a[p];    mid=RamdomizePartition(a, p, r);     if( mid &gt;= k)        return (RSelect(a, p, mid, k));     else         return (RSelect(a, mid + 1, r, k - mid);              &#125;   //初略时间分析:  T(n) = T(9n/10) + O(n) = O(n)</code></pre></li></ol><p><strong>方法三</strong>：线性时间选择算法 Select() ：对快速排序的改进，最坏时间$O(n)$。</p><ol><li>将 n 个元素，分成$\lceil n/5 \rceil$组，取出每组的中位数（第三小的元素）</li><li>取出$\lceil n/5 \rceil$个中位数的中位数（Select函数可以取中位数）</li><li>利用快排中的分解函数 Partition()，以所求中位数为基准，划分 a[p : r] 为两段。</li><li>取其中一段进行递归。</li></ol><pre><code class="c++">template &lt;class Type&gt;Type Select(Type a[], int p, int r, int k)&#123;        if( r - p &lt; 75 )     &#123;         直接对数组a[p:r]排序;          return a[p+k-1];    &#125;     for( int i = 0; i &lt;= (r - p - 4) / 5 ; i++ )      //分 n/5 组, 取各组中位数    &#123;        swap(a[p + 5*i]至a[p+5*i+4]的第3小元素, a[p+i]);    &#125;    Type x = Select(a, p, p+(r-p-4)/5, (r-p-4)/10); //取中位数的中位数, T(n/5)        int i = Partition(a, p, r, x), j = i - p + 1;         if ( k == j )         return a[i];    else if ( k &lt; j )         return Select(a,p,i-1,k);    //选择左片递归, 最多T(3n/4)    else         return Select(a,i+1,r,k-j);  //选择右片递归, 最多T(3n/4) &#125;</code></pre><p>时间复杂度分析：</p><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN/img/image-20200322212752169.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN/img/image-20200322212752169.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="zoom: 67%;" /><p>总结：算法优化的历程</p><table><thead><tr><th>算法</th><th align="center">快排</th><th align="center">随机选择</th><th align="center">线性时间选择</th></tr></thead><tbody><tr><td>时间复杂度</td><td align="center">$O(nlog(n))$</td><td align="center">$O(n) – O(n^2)$</td><td align="center">$O(n)$</td></tr><tr><td>基准值</td><td align="center">a[p]</td><td align="center">random</td><td align="center">中位数</td></tr></tbody></table><p>附：line-time-select.c</p><pre><code class="c++">#include &lt;stdio.h&gt;#define MAX 2000010int num[MAX];// 选择排序void slsort(int p, int q)&#123;    for (int i = p + 1; i &lt;= q; i++)    &#123;        int temp = num[i], j = i - 1;        while (j &gt;= p)        &#123;            if (num[j] &gt; temp)            &#123;                num[j + 1] = num[j];                j--;            &#125;            else                break;        &#125;        num[j + 1] = temp;    &#125;&#125;// 分解函数int Partition(int p, int q, int mid)&#123;    int i = p, j = q;    while (i &lt;= q &amp;&amp; j &gt;= p)    &#123;        while (num[i] &lt; mid)&#123;i++;&#125;        while (num[j] &gt; mid)&#123;j--;&#125;        if (i &gt;= j)            break;        else        &#123;            int temp = num[i];            num[i] = num[j];            num[j] = temp;            i++, j--;        &#125;    &#125;    return j;&#125;// 选择函数int Select(int p, int q, int k)&#123;    if (q - p &lt; 75)    &#123;        slsort(p, q);        return num[p + k - 1];    &#125;    // 选出 n/5 组中每个组的中位数    for (int i = 0; i &lt;= (q - p - 4) / 5; i++)    &#123;        slsort(p + 5 * i, p + 5 * i + 4);        int temp = num[p + 5 * i + 2];        num[p + 5 * i + 2] = num[p + i];        num[p + i] = temp;    &#125;    // 选出各种中位数的中位数 mid    int mid = Select(p, p + (q - p - 4) / 5, ((q - p - 4) / 5 + 1) / 2);    // 以 mid 为基准进行分解    int mid_id = Partition(p, q, mid);    int mid_rank = mid_id - p + 1;    // 递归条件判断    if (k == mid_rank)    &#123;        return num[mid_id];    &#125;    else if (k &lt; mid_rank)    &#123;        return Select(p, mid_id, k);    &#125;    else    &#123;        return Select(mid_id + 1, q, k - mid_rank);    &#125;&#125;int main(int argc, char const *argv[])&#123;    int i = 0, k;    while (scanf(&quot;%d&quot;, &amp;num[i]) != EOF) &#123;i++;&#125;    scanf(&quot;%d&quot;, &amp;k); // 选择第几小的元素    if( k &gt; i)        printf(&quot;error!\n&quot;);    else        print(&quot;%d\n&quot;, Select(0, i, k));    return 0;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows更新git——443错误</title>
      <link href="/2020030264606/"/>
      <url>/2020030264606/</url>
      
        <content type="html"><![CDATA[<p>最近Windows系统总是在通知栏提醒我 <strong>git</strong> 需要更新，不胜其烦……</p><span id="more"></span><h2 id="1、更新Git"><a href="#1、更新Git" class="headerlink" title="1、更新Git"></a>1、更新Git</h2><p>更新 <strong>git</strong> 很简单，只需要打开 <strong>cmd</strong>，输入：</p><pre><code class="powershell"># 如果git是2.17.1以前的版本，使用下一行的命令git update# 如果git是2.17.1以后版本，采用以下命令git update-git-for-windows</code></pre><p>或许会有如下报错：</p><pre><code class="powershell">curl: (35) OpenSSL SSL_connect: SSL_ERROR_ZERO_RETURN in connection to github-production-release-asset-2e65be.s3.amazonaws.com:443</code></pre><p>出现443的错误，以及下载速度奇慢无比。于是估计是由于<strong>GFW</strong>的原因，一般修改git的网络代理即可。</p><h2 id="2、解决git-443错误"><a href="#2、解决git-443错误" class="headerlink" title="2、解决git-443错误"></a>2、解决git-443错误</h2><p>查询当前代理:</p><pre><code class="powershell">git config --global http.proxy</code></pre><p>修改代理，设置git使用SSR代理服务器：</p><pre><code class="powershell"># 端口号不同，一般为1080git config --global http.proxy &quot;127.0.0.1:端口号&quot;</code></pre><p>修改代理后，再次尝试 <code>git update-git-for-windows</code> ，成功更新 <strong>git</strong>.</p><p>取消代理：</p><pre><code class="powershell">#避免以后git总是使用代理，git config --global --unset http.proxy</code></pre>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anaconda:安装 &amp; 指令入门</title>
      <link href="/2020021155263/"/>
      <url>/2020021155263/</url>
      
        <content type="html"><![CDATA[<p>Anaconda是一个免费开源的Python和R语言的发行版本，致力于简化包管理和部署，常用于计算科学（数据科学、机器学习、大数据处理和预测分析。</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/python-logo.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/python-logo.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h2 id="一、Python简介"><a href="#一、Python简介" class="headerlink" title="一、Python简介"></a>一、Python简介</h2><p>​    Python是一种解释型语言，支持Windows，Linux，Mac平台。Python功能强大，有丰富的第三方库，能够提供各种应用场景的支持。</p><ul><li>关于Python版本，存在 Python2.x 和 Python3.x。官方说法：2020年1月1日，Python2将停止更新和维护。因此建议学习使用Python3。</li><li>Python 的优势：<ul><li>Python是一门高级语言，所谓“高级”：是指抽象程度上比C等语言更高级。因此Python更接近人类思维，更容易上手。</li><li>Python有良好的生态，丰富的第三方库，将Python武装成能应对Web开发、网络安全、游戏开发、网络爬虫、数据处理、机器学习等领域的全能型语言。</li><li>Python是胶水语言，能够粘合本不兼容的代码，如：Cpython、Jython.</li></ul></li><li>Python的劣势：<ul><li>Python的性能劣势，不够底层，不如C快。但是经过优化，Python的速度在某些情况下，不弱于C</li><li>Python是动态语言，大型程序难以维护、修改重构。<em>动态一时爽，事后火葬场。。。</em></li></ul></li></ul><h2 id="二、Python安装"><a href="#二、Python安装" class="headerlink" title="二、Python安装"></a>二、Python安装</h2><blockquote><p>大一时安装Python的惨像，已使我目不忍视了；失败报错，尤使我耳不忍闻。我还有什么话可说呢？</p></blockquote><p>​    想要在自己的系统中运行Python就需要安装Python解释器，就像运行C语言需要 gcc 编译器一样。可以选择下载Python安装，但我更建议安装Anaconda。Wiki百科介绍如下：</p><blockquote><p><strong>Anaconda</strong>是一个免费开源的Python和R语言的发行版本，用于计算科学（数据科学、机器学习、大数据处理和预测分析，Anaconda致力于简化包管理和部署。<strong>Anaconda的包使用软件包管理系统Conda进行管理</strong>。超过1200万人使用Anaconda发行版本，并且Anaconda拥有超过1400个适用于Windows、Linux和MacOS的数据科学软件包</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda-logo.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda-logo.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>​    简单来说Anaconda提供了1摩尔的扩展包，以及一个非常好用的管理这些包的工具conda。也就是Python是简约线条，而Anaconda是极致色彩。</p><p>​    Python第三方的模块库很多，之间的依赖关系复杂，需要一个工具来管理这些包。主流包管理工具有pip和conda两种，conda功能相对完善，因此推荐conda。</p><h3 id="Windows10安装Anaconda"><a href="#Windows10安装Anaconda" class="headerlink" title="Windows10安装Anaconda"></a>Windows10安装Anaconda</h3><ol><li>下载Anaconda，推荐<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/?C=M&O=D">清华镜像源</a>。</li></ol><p>下载最新版本的Anaconda，注意64位系统选择x86_64版本，如图：<br>   <img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_1.jpg" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_1.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><ol start="2"><li>一路 next 或者 I agree ，直到出现下图：</li></ol><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_2.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_2.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="zoom:50%;" /><ul><li>建议更改默认路径，因为之后安装多个虚拟环境后，Anaconda会占较大的存储空间。我这里更改为<strong>D:\Anaconda</strong>。</li></ul><ol start="3"><li>在下一个界面，勾选两个选项：</li></ol><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_3.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_3.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="zoom:50%;" /><ul><li>第一个选项：添加Anaconda到系统环境变量。目的是：<em>在系统的任何位置打开命令终端都能够运行Python</em>，这为我们以后配置Python的开发环境如<a href="http://www.sublimetextcn.com/">SublimeText3</a>，<a href="https://code.visualstudio.com/">Vs Code</a> 提供很大的便利。</li><li>第二个选项：设置Anaconda为默认的Python解释器。</li></ul><ol start="4"><li>之后一路next or install 就可以了，安装完成后再Windows开始菜单里会出现下图所示的快捷方式：</li></ol><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_4.jpg" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_4.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="zoom:70%;" /><ul><li>第一个是Anaconda的一个管理界面</li><li>第二、三个是Anaconda的两个命令行工具</li><li>第四个是Jupyter notebook，一个基于Web的笔记本式交互开发环境，支持Markdown，非常适合学习使用。</li><li>第六个是Spyder一个轻量级的文本式开发环境（没咋用过。。。）</li></ul><ol start="5"><li><p>验证Python是否安装成功</p><ol><li><p>按下win + R，在窗口中输入<code>cmd</code></p></li><li><p>在cmd命令行中输入</p></li></ol></li></ol><pre><code class="bash">python</code></pre><ol start="3"><li>如果出现以下内容，则安装正确</li></ol><pre><code class="bash">Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 21:48:41) [MSC v.1916 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt;</code></pre><ol start="4"><li>如果出现以下内容，则安装有误</li></ol><pre><code class="bash">&#39;python&#39; 不是内部或外部命令，也不是可运行的程序或批处理文件。</code></pre><ul><li><p>如果有误建议重启系统，再次尝试验证。如果仍然错误，建议检查是否已经添加Anaconda到系统环境变量：</p><p><img src="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_6.png" class="lazyload" data-srcset="https://cdn.jsdelivr.net/gh/xuzf-git/CDN@master/img/Python/basis-1/Anaconda_6.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p></li></ul><h3 id="Linux安装Anaconda"><a href="#Linux安装Anaconda" class="headerlink" title="Linux安装Anaconda"></a>Linux安装Anaconda</h3><ol><li>下载Anaconda，同上。得到<strong>Anaconda-x.x.x-Linux-x86_64.sh</strong>文件</li><li>打开终端，cd 到下载路径：输入以下命令：</li></ol><pre><code class="bash">bash Anaconda-x.x.x-Linux-x86_64.sh  # 注意换成自己下载的对应文件名 </code></pre><ol start="3"><li>之后一路Enter，如果遇到选择就输入yes.</li><li>完成后，重启终端，输入：</li></ol><pre><code class="bash"> python</code></pre><ol start="5"><li>如果得到以下内容，说明Anaconda安装正确。</li></ol><pre><code class="bash">Python 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0] :: Anaconda, Inc. on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; </code></pre><h2 id="三、Anaconda配置及conda指令"><a href="#三、Anaconda配置及conda指令" class="headerlink" title="三、Anaconda配置及conda指令"></a>三、Anaconda配置及conda指令</h2><h3 id="1-添加国内镜像源"><a href="#1-添加国内镜像源" class="headerlink" title="1. 添加国内镜像源"></a>1. 添加国内镜像源</h3><p>利用conda安装很多packages时，会发现下载很慢，这是因为Anaconda的服务器在国外，为了提高下载速度，可以添加国内的镜像源。</p><h4 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h4><p>打开Anaconda Prompt，输入以下命令：</p><pre><code class="bash"># 添加Anaconda的TUNA镜像conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/# 需要pytorch的话，添加pytorch镜像conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ # 设置搜索时显示通道地址conda config --set show_channel_urls yes</code></pre><h4 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h4><ol><li>修改 ~/.condarc文件</li></ol><pre><code class="bash">vi ~/.condarc</code></pre><ol start="2"><li>添加以下内容</li></ol><pre><code class="bash">channels:  - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/  - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/  - defaultsshow_channel_urls: true</code></pre><p>输入<code>:wq</code>，保存退出。</p><h3 id="2-删除镜像源"><a href="#2-删除镜像源" class="headerlink" title="2.删除镜像源"></a>2.删除镜像源</h3><pre><code class="bash"># 恢复成默认下载源conda config --remove-key channels</code></pre><h3 id="3-Anaconda升级"><a href="#3-Anaconda升级" class="headerlink" title="3. Anaconda升级"></a>3. Anaconda升级</h3><pre><code class="bash">conda update conda conda update anaconda</code></pre><h3 id="4-Anaconda-卸载"><a href="#4-Anaconda-卸载" class="headerlink" title="4. Anaconda 卸载"></a>4. Anaconda 卸载</h3><h4 id="Windows-1"><a href="#Windows-1" class="headerlink" title="Windows"></a>Windows</h4><p>依次执行以下步骤</p><ol><li>打开Anaconda Prompt，输入以下命令，删除所有配置文件和目录</li></ol><pre><code class="bash"># 安装anaconda-cleanconda install anaconda-clean# 运行anaconda-cleananaconda-clean --yes</code></pre><ol start="2"><li>手动删除anaconda安装目录下的 envs和pkgs文件夹</li><li>在控制面板中，卸载anaconda程序</li></ol><h4 id="Linux-1"><a href="#Linux-1" class="headerlink" title="Linux"></a>Linux</h4><p>打开命令行，输入以下命令，删除所有配置文件和应用程序</p><pre><code class="bash"># 安装anaconda-cleanconda install anaconda-clean# 运行anaconda-cleananaconda-clean --yes# 删除程序rm -rf ~/anaconda3</code></pre><h3 id="5-conda-包管理指令"><a href="#5-conda-包管理指令" class="headerlink" title="5.conda 包管理指令"></a>5.conda 包管理指令</h3><table><thead><tr><th>指令</th><th>作用</th></tr></thead><tbody><tr><td>codna list</td><td>列出所有已安装的包</td></tr><tr><td>conda install package_name</td><td>安装软件包及其依赖项</td></tr><tr><td>conda remove package_name</td><td>卸载包</td></tr><tr><td>conda update/upgrade –all</td><td>更新环境中所有已安装的包</td></tr><tr><td>conda info</td><td>显示当前conda环境的基本信息</td></tr><tr><td>conda help</td><td>显示conda指令的帮助命令</td></tr><tr><td>conda create</td><td>创建虚拟环境</td></tr><tr><td>conda -V</td><td>显示conda 版本信息</td></tr></tbody></table><h3 id="6-conda-环境管理指令"><a href="#6-conda-环境管理指令" class="headerlink" title="6. conda 环境管理指令"></a>6. conda 环境管理指令</h3><table><thead><tr><th>指令</th><th>作用</th></tr></thead><tbody><tr><td>conda create -n env_name python=x.x</td><td>创建名为env_name的虚拟环境</td></tr><tr><td>conda activate env_name</td><td>进入env_name环境</td></tr><tr><td>conda deactivate</td><td>离开环境，回到base环境</td></tr><tr><td>conda env list</td><td>列出环境</td></tr><tr><td>conda env remove -n env_name</td><td>删除env_name环境</td></tr><tr><td>conda env export &gt; environment.yaml</td><td>将环境导出为YAML文件</td></tr><tr><td>conda env create -f environment.yaml</td><td>加载环境</td></tr></tbody></table><h2 id="四、结语"><a href="#四、结语" class="headerlink" title="四、结语"></a>四、结语</h2><blockquote><p>路漫漫其修远兮，吾将上下而求索。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pyhon </tag>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
